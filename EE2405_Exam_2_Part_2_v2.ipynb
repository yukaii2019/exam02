{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EE2405_Exam_2_Part_2_v2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DI1ebUOX16FD",
        "colab_type": "text"
      },
      "source": [
        "# EE2405 Embedded System Lab Exam #2 Part 2\n",
        "\n",
        "**Please click on \"Open in playground\" at the upper-left corner to create a copy for you.**\n",
        "\n",
        "---\n",
        "\n",
        "**Please fill in correct statements in the right of the codes to finish the scripts.**  \n",
        "Data sample is generated with a quadratic function and we will train a regression model to fit the data.  \n",
        "And we convert and interpret the trained model with a Tensorflow lite APIs.\n",
        "\n",
        "You can run the script again after you fill all the blank to check the outputs.\n",
        "\n",
        "---\n",
        "\n",
        "The Method to Download the Jupyter Notebook:  \n",
        "File > Download .ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HC3FqFF1zRJW",
        "colab_type": "text"
      },
      "source": [
        "## Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhRpD2SsyQrm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TensorFlow is an open source machine learning library\n",
        "import tensorflow as tf\n",
        "# Numpy is a math library\n",
        "import numpy as np\n",
        "# Matplotlib is a graphing library\n",
        "import matplotlib.pyplot as plt\n",
        "# math is Python's math library\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YztOxOMy0eUB",
        "colab_type": "text"
      },
      "source": [
        "## Generate Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgApv0fcwU3I",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "2c50df7a-472b-421b-abbc-9f0359919261",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "# We'll generate this many sample datapoints\n",
        "############################################################\n",
        "#@markdown Please fill in the number of samples (the sample should be large enough, but not too large for computation).\n",
        "SAMPLES =  200#@param {type:\"number\"}\n",
        "############################################################\n",
        "\n",
        "\n",
        "############################################################\n",
        "#@markdown Please fill in your student id, which is the random seed.\n",
        "student_id =  107033137#@param {type:\"number\"}\n",
        "np.random.seed(student_id)\n",
        "############################################################\n",
        "\n",
        "# Generate a uniformly distributed set of random numbers\n",
        "# in the range from 0 to 10\n",
        "x_values = np.random.uniform(low=0, high=10, size=SAMPLES)\n",
        "\n",
        "# Shuffle the values to guarantee they're not in order\n",
        "np.random.shuffle(x_values)\n",
        "\n",
        "############################################################\n",
        "#@markdown Please fill in the statement to generate `y_values` with a quadratic function `y = x^2-5x+1`?\n",
        "script = \"y_values = x_values*x_values-5*x_values +1\" #@param {type:\"string\"}\n",
        "exec(script)\n",
        "############################################################\n",
        "\n",
        "# Plot our data.\n",
        "# The 'b.' argument tells the library to print blue dots.\n",
        "plt.plot(x_values, y_values, 'b.')\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGVnrxG10nHh",
        "colab_type": "text"
      },
      "source": [
        "## Add some noise\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR7y-_3_x-Lz",
        "colab_type": "code",
        "outputId": "cbc563e5-e239-4033-8469-86583b9b53b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "# Add a small random number to each y value\n",
        "y_values += np.random.randn(*y_values.shape)\n",
        "\n",
        "# Plot our data\n",
        "plt.plot(x_values, y_values, 'b.')\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SI4ZI4Wv4B_y",
        "colab_type": "text"
      },
      "source": [
        "## Split our data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1zguEyz393e",
        "colab_type": "code",
        "outputId": "d1fd26b5-1e8c-4c34-f247-0c97dc87841a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "# We'll use 60% of our data for training and 20% for testing. The remaining 20%\n",
        "# will be used for validation. Calculate the indices of each section.\n",
        "TRAIN_SPLIT =  int(0.6 * SAMPLES)\n",
        "TEST_SPLIT = int(0.2 * SAMPLES + TRAIN_SPLIT)\n",
        "\n",
        "# Use np.split to chop our data into three parts.\n",
        "# The second argument to np.split is an array of indices where the data will be\n",
        "# split. We provide two indices, so the data will be divided into three chunks.\n",
        "x_train, x_test, x_validate = np.split(x_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "y_train, y_test, y_validate = np.split(y_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "\n",
        "# Double check that our splits add up correctly\n",
        "assert (x_train.size + x_validate.size + x_test.size) ==  SAMPLES\n",
        "\n",
        "# Plot the data in each partition in different colors:\n",
        "plt.plot(x_train, y_train, 'b.', label=\"Train\")\n",
        "plt.plot(x_test, y_test, 'r.', label=\"Test\")\n",
        "plt.plot(x_validate, y_validate, 'y.', label=\"Validate\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD4CAYAAAAJmJb0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3dfXxU5Znw8d81k0ygShNNqVgpL4tvREOCRuspigfjW9dWadVWKg1Wt2x9qdLVuqVdn/J5rOCubE3rulUoKDzVUle2ii8t1SlHsRytQUigUQuoWCooTTcRtiWTmXM/f5yZZBImCSQzmcnM9f18+GTmnJk590zCde65zn1ftxhjUEoplZ8C2W6AUkqpzNEgr5RSeUyDvFJK5TEN8koplcc0yCulVB4rynYDkn3sYx8zEyZMyHYzlFJqWNm4ceOfjTGjU+3LqSA/YcIEGhoast0MpZQaVkRkZ2/7NF2jlFJ5TIO8UkrlMQ3ySimVx3IqJ59KR0cHu3bt4sCBA9luyrAwYsQIxo4dS3FxcbabopTKATkf5Hft2sWoUaOYMGECIpLt5uQ0YwwtLS3s2rWLiRMnZrs5SqkckJZ0jYi8IyJbRGSziDTEtx0tIs+JyLb4z6MG8toHDhygvLxcA/whEBHKy8v1W49SqlM6c/IzjDHVxpia+P1vA2FjzAlAOH5/QDTAHzr9rJQaflwXFi3yf6ZbJtM1lwF2/PYKwAH+OYPHU0qpYcd1obYWIhEIhSAcBstK3+unqydvgF+LyEYRmRvfdowxZnf89h7gmFRPFJG5ItIgIg179+5NU3PSp6WlherqaqqrqxkzZgzHHXdc5/1IJNLncxsaGrj55puHqKVKqeHIcfwAH4v5Px0nva+frp782caYP4nIx4HnROSN5J3GGCMiKVcnMcYsAZYA1NTU5NwKJuXl5WzevBmABQsWcOSRR3Lbbbd17o9GoxQVpf4Ya2pqqKmpSblPKaUAbNvvwSd68rad3tdPS5A3xvwp/vMDEfkFcCbwvogca4zZLSLHAh+k41iHwnX9s6Ftp/drT8I111zDiBEj2LRpE9OmTeOqq67illtu4cCBA4wcOZKHHnqIk046CcdxWLx4MU8//TQLFizg3Xff5a233uLdd99l3rx52stXqoC5Lmxb6XIuDq/U2zzdYmUkZg06yIvIEUDAGLMvfvtC4P8Ca4A5wN3xn08O9liHItP5rYRdu3axYcMGgsEgH374IevXr6eoqIjnn3+e73znO6xevfqg57zxxhusW7eOffv2cdJJJ3H99dfreHalCpDrwnzb5dlILSEijC0JUbkuM8EqHT35Y4BfxEd1FAGPGmN+JSKvAo+JyHXATuCLaThWv1LltzIR5K+88kqCwSAAbW1tzJkzh23btiEidHR0pHzOJZdcQklJCSUlJXz84x/n/fffZ+zYselvnFIqZ6TKLDgOTOtwCBGhiBixDAarQQd5Y8xbQFWK7S1A7WBf/3BlOr+VcMQRR3TevuOOO5gxYwa/+MUveOedd7B7OWhJSUnn7WAwSDQazUzjlFI5obfMgm3D/GKbSCSEIUIgg8Eq52e8Hi7L8j/ITObke2pra+O4444D4OGHH878AZVSw0JvmYWKCpc7n3dYs7Yeq6WF8XV2xoJV3gV58D+roQjuCbfffjtz5szh+9//PpdccsnQHVgpldN6ZhbKy+G++1wqK2uBCJ+4MERZVRhKMxewxJjcGbVYU1Njei4a8vrrrzN58uQstWh40s9MqdyRyMmXl8O8eXD55Yu45po7CAZjQJCJE+9k/Pj5gzqGiGxMqjbQjZYaVkqpDLIsmD8fWlr8Hv1rr9l0dIQwJkggEKKszM7o8TXIK6XUEEikbt580+I73wlTVHQnVVVhSjOYqoE8zckrpVSu6T4oxMIaoguHGuSVUiqDeo6TH8pBIaBBXimlMsN12bnSYf5ym5diVkZn4PdFc/JKKZVuS5bA9Ol88oF/4dlILWfEXNrb019h8lBoT74fLS0t1Nb6E3f37NlDMBhk9OjRAPzud78jFAr1+XzHcQiFQnz605/OeFuVUtmTSMt8ttyl8qabIBolAIRox8bhZc+ivHzo26VBvh/9lRruj+M4HHnkkRrklcpjifIFkya5jK5ewCdPiFLW7C+04RHAwSYQ8IdRDrX8TNdkci0tYOPGjZx77rmcfvrpXHTRReze7a+N8qMf/YiKigqmTJnCVVddxTvvvMMDDzzAvffeS3V1NevXr89Ie5RS2eU4foC/555aJl7zPE3/bvhLheAFiplXdD+vBi1KSjJXS6sv+deTz3CtYWMM3/jGN3jyyScZPXo0P//5z/nud7/L8uXLufvuu3n77bcpKSmhtbWVsrIyvv71rx92718pNbzYNrz5pkNxcYRg0KPDBFhdfT4l0xfwlTqLTzpDV0urp/wL8hmuNdze3s7WrVu54IILAIjFYhx77LEATJkyhauvvpqZM2cyc+bMtB1TKZXbLAs8z+ZvfwsRjUaIRkP8+PUF3H+/lZVhk8nyL8hnuNawMYZTTjkFN0Uq6JlnnuHFF1/kqaee4q677mLLli1pPbZSKndNm2bR1hamqcnh9dftzgCfbfkX5DNca7ikpIS9e/fiui6WZdHR0cEf/vAHJk+ezB//+EdmzJjB2WefzapVq9i/fz+jRo3iww8/TGsblFK5qbTU4pxzLM45J9st6ZJ/QR4yOq0sEAjw+OOPc/PNN9PW1kY0GmXevHmceOKJzJ49m7a2Nowx3HzzzZSVlfG5z32OK664gieffJL77ruPc3Lpt6+UyntaajgP6WemVHakWupvKPRVajg/e/JKKTUE2tpcWlsdyspsmputTA7sGzAN8kopNQBtbS6NjbV4XoRAIERjY5hIxMrUwL4By8/JUEoplWGtrQ6eFwFieF6E6mqHUAiCwYwM7Bsw7ckrpdQAlJXZBAKhzp78lCl2Jgf2DZgGeaWUGoDSUouqqnBnTr60NPsTn1LRIK+UUgNUWmplfPm+wdKcfD9mzJjB2rVru22rr6/n+uuvT/l427ZJDAP9+7//e1pbWw96zIIFC1i8eHGfx33iiSdobm4eYKuVUsqXtiAvIkER2SQiT8fvTxSRV0Rku4j8XET6Lryeo2bNmsWqVau6bVu1ahWzZs3q97nPPvssZWVlAzquBnmlckSGq9pmWjp78rcAryfd/1fgXmPM8cD/ANel8Vh9amtz2blzEW1tg/+lXHHFFTzzzDNEIhEA3nnnHd577z1+9rOfUVNTwymnnML3vve9lM+dMGECf/7znwG46667OPHEEzn77LN58803Ox+zdOlSzjjjDKqqqrj88sv561//yoYNG1izZg3f+ta3qK6uZseOHezYsYOLL76Y008/nXPOOYc33nhj0O9NKdWPRFXbO+7wfw7DQJ+WIC8iY4FLgJ/E7wtwHvB4/CErgCEpy5gYu/r223fQ2Fg76EB/9NFHc+aZZ/LLX/4S8HvxX/ziF7nrrrtoaGigqamJF154gaampl5fY+PGjaxatYrNmzfz7LPP8uqrr3bu+8IXvsCrr75KY2MjkydPZtmyZXz605/m0ksv5Z577mHz5s1MmjSJuXPnct9997Fx40YWL17MDTfcMKj3pZQ6BKmq2g4z6brwWg/cDoyK3y8HWo0x0fj9XcBxqZ4oInOBuQDjxo0bdEN6jl1tbXUGfWEkkbK57LLLWLVqFcuWLeOxxx5jyZIlRKNRdu/eTXNzM1OmTEn5/PXr1/P5z3+ej3zkIwBceumlnfu2bt3Kv/zLv9Da2sr+/fu56KKLDnr+/v372bBhA1deeWXntvb29kG9J6XUIchwVduhMOggLyKfBT4wxmwUEftwn2+MWQIsAb92zWDb03PsalnZYTfpIJdddhnf/OY3ee211/jrX//K0UcfzeLFi3n11Vc56qijuOaaazhw4MCAXvuaa67hiSeeoKqqiocffhgnRU/B8zzKyso6lyFUSg2ReFXbnSsdXsDmBCxyeyzNwdKRrpkGXCoi7wCr8NM0PwTKRCRxEhkL/CkNx+pXYuzqxIl3UlUVTsvwpiOPPJIZM2Zw7bXXMmvWLD788EOOOOIISktLef/99ztTOb2ZPn06TzzxBH/729/Yt28fTz31VOe+ffv2ceyxx9LR0cEjjzzSuX3UqFHs27cPgI9+9KNMnDiR//qv/wL8mvaNjY2Dfl9Kqf65WExeMZ9rl1rDMi0/6CBvjJlvjBlrjJkAXAX8xhhzNbAOuCL+sDnAk4M91qEqLbUYP35+Wsevzpo1i8bGRmbNmkVVVRVTp07l5JNP5stf/jLTpk3r87mnnXYaX/rSl6iqquIzn/kMZ5xxRue+O++8k0996lNMmzaNk08+uXP7VVddxT333MPUqVPZsWMHjzzyCMuWLaOqqopTTjmFJ58cso9TqYLlurBgAbS3D9+0fFpLDcfTNbcZYz4rIn+H37M/GtgEzDbG9JlI1lLD6aGfmVKDlxhY094OngeBAJSU5E51yWRDVmrYGOMATvz2W8CZ6Xx9pZQaKomBNYkAf/75fq8+1wJ8f3TGq1JKpZAYWBMM+j344RjgYZjUrjHG4A+9V/3JpZW+lBpOeq7qlOHloodMzgf5ESNG0NLSQnl5uQb6fhhjaGlpYcSIEdluilLDSiL/3nNVp1ysKnm4cj7Ijx07ll27drF3795sN2VYGDFiBGPHjs12M5QaVlJNbB3uwT0h54N8cXExEydOzHYzlFJ5LA8mtvYq54O8UkplWr7k31PRIK+UKmhtbS6trQ4VFTZWPkX3OA3ySqmClaham6h1la5SKLlEx8krpQpWqqq1+UaDvFKqYCWq1kIwbVVrc42ma5RSBStRtba11aGszM67VA1okFdKFbjSUisvg3uCpmuUUiqPaZBXSqk8pkFeKaXymAZ5pZTKYxrklVIqj2mQV0oVDNeFRYuG32Lcg6FDKJVSBaG3mvH5TnvySqmC4DgwaZLLl760iEmTXBwn2y0aGtqTV0rlrUSFybIym+nTYerUWoqLI3R0hBg1Kgzkf1deg7xSKu+0tbns2bOSPXsewpgogUCIY46ZQ0eHX4wsGIwwdqyDBnmllMoxPRfc7qmrfPABjDGIEK80CYFAqLOscD4WI0tFg7xSatjo7+Kp68If/uAwblwEEQOA5wmBQIgxY+oYM6Yur4uRpaJBXik1bPS14HbiBDBpks0994QoKooQiwVZu/ZaJk6sw7b9BxZKcE/QIK+UGjb6WnA7cQLYutXiW98KM3Wqw6ZNNjt2WITDWWpwDhh0kBeREcCLQEn89R43xnxPRCYCq4ByYCPwFWNMZLDHU0oVrooKl7VrHTZvtqmpsbqlapJPADt2WHzjGxaTJ+ffwtyHKx09+XbgPGPMfhEpBl4SkV8C/wTca4xZJSIPANcBP07D8ZRSBSh5PdaqqhAVFWFc1+p2ETYc7vuibCEadJA3xhhgf/xucfyfAc4DvhzfvgJYgAZ5pdQA9VyPtanJ4aKLrM7UTX09tLRogO8pLTl5EQnip2SOB+4HdgCtxpho/CG7gON6ee5cYC7AuHHj0tEcpVQeSqzHmhgCuXatzYEDYAy0t8ONN/q3C6lkwaFIS1kDY0zMGFMNjAXOBE4+jOcuMcbUGGNqRo8enY7mKKXyUGI91okT7yQYDHPPPRbGdO33vO6jbpQvraNrjDGtIrIOfxpZmYgUxXvzY4E/pfNYSqnCk1iP9dFHIRrtvq+oyA/yPUfdFLp0jK4ZDXTEA/xI4ALgX4F1wBX4I2zmAE8O9lhKKQV+EA8E/N57wrXXwrhxmpPvKR09+WOBFfG8fAB4zBjztIg0A6tE5PvAJmBZGo6llFJYFtx/P9x0k997LymBujoN7qmkY3RNEzA1xfa38PPzSimVdnPnQmWlDpnsj854VUoNW5alwb0/umiIUiqnFeKSfemkPXmlVM4q1CX70kl78kqpnJWq6qQ6PNqTV0rlnMTCIOXlvVedVIdGg7xSKqf0TNFoTZrB0SCvlMopPVM0LS0wf362WzV8aZBXSuUU24azgy7TPIffBu3OFZ3UwGiQV0rlFAuXsNQiRDASIkgYvxyWGggdXaOUyi2OQzAaIWBiBKM6pGawNMgrpXKLbRMrChGTILEiHVIzWJquUUplXVubS2urQ1mZTTMW802YaTj81tgswtJkzSBokFdKZY3rQkODS2VlLeCv+NTYGOalmMULxiIY87M1OnRy4DRdo5TKisR4+N2vrMSLHSCxdmt1tUMoBMGgToBKB+3JK6WywnHgtHaXWzYt583ZBs+AFMGkSeWEw1pCOF00yCulssK24W8Bh/LmGMf/B2ybB8Z4bN8+j6qqSiyN7mmh6RqlVFZYFpz2TzbRQIhImWAEEIPnRWhtdbLdvLyhQV4plRWuC1++z+J8wjze9I8gJUCQQCBEWZmd7eblDU3XKKWGlOvCtpUuH33N4bR2m996Fi83W9z7+zouvdQfRllaqqmadNEgr5QaEm1tLk1NDg9+o5wljfMIEeFCQlwYCPNayKKmxmL8eA3u6aZBXimVEckTnAAaG2uJxSJ89e4AB26N8ZFmD4jw/TkrCX7VoaLCRmvUpJ8GeaVU2rW1uTQ21uJ5/gSnY46Zg+dFEIlBkeEv1QFGNQt/qQjC7IeIxaI0NoaoqgprqibNNMgrpdKutdXB8yIkJjgBBAIhPC+CIcR3N9fzd7QgU9/lAlmKxB/X2upokE8zDfJKqbQrK7PjQb0dEWHUqKmMGVNHa6vDrl0220ogNNth//6pXCghEiUNdFRN+okxJttt6FRTU2MaGhqy3QylVBq8994Stm27CWNiBAIlfiqmGdoaVrLplIcwEkUkxIkn1tPR0aKjagZBRDYaY2pS7Rv0OHkR+aSIrBORZhH5vYjcEt9+tIg8JyLb4j+PGuyxlFLDR8eOTRgvCnh+KqZpJcyYQevLD4Bp9/PzROjoaGH8+Pka4DMkHZOhosCtxpgK4CzgRhGpAL4NhI0xJwDh+H2lVCFwXYp/8BMkZiAGAYooW7sH2tsp2wyBDsATTdEMgUEHeWPMbmPMa/Hb+4DXgeOAy4AV8YetAGYO9lhKqeGhrWEl2/8xihEQD47f8RlKW8YAUNoMVbfCxK1n6GiaIZDWsgYiMgGYCrwCHGOM2R3ftQc4ppfnzBWRBhFp2Lt3bzqbo5TKktZq8IqBIBiBjhPHQF2dXztYhNLtIcafUa8BfgikLciLyJHAamCeMebD5H3Gv7qb8gqvMWaJMabGGFMzevTodDVHKZVFZVPqCARLwAiBohLKptT5FckcB+66S1cCGUJpGUIpIsX4Af4RY8x/xze/LyLHGmN2i8ixwAfpOJZSKje4bu8130tLLaqmruuc8drZY7csDe5DbNBBXkQEWAa8boz5QdKuNcAc4O74zycHeyylVG5IrOoUicDZQZcV1zqMn1oOLS2dUb+01NJ0TA5IR09+GvAVYIuIbI5v+w5+cH9MRK4DdgJfTMOxlFI5wHH8AH9GzOXZWC0jHmgHPAxCLFjM6//pUDlXA3wuGHSQN8a8BEgvu2sH+/pKqdxj2/411PMOOIRMhH0VHq3VULbZ8NHmCC/fsJL9lZZmZnKAljVQSh02y4JwGLattNn3cpAti2J4xf749ym3Qux1vbaaK3RlKKXUgFgW1P3Y4sMfXYsXEgiCVwQt1UFWFddh29luoQIN8kqpQSqbUkegaAQQQCjm1Yn/ySJHUzW5QtM1SqnD0nPoZGmpRVVVuHO45Lnna3TPJRrklVL9SgT28nKYN88fWRMK+Xn5RKDX4ZK5SYO8UqpPyWPiAwGIxcDz/Pt6cTX3aZBXSvUpMSY+FgNjQMT/FwyiF1eHAQ3yShU414WVK/3bdXUH98wTY+IjESgq8nvxnucHepX7NMgrVcBcF2bMgPZ2//7y5fEUDF1XVy3LIhz27777Lixd6vfoo1FN1wwHGuSVKmCJVExCRwdsW+lirajtdnXVsvwhka4LK1Z07dJ0Te7TIK9UAbNtPwXT0eHfNwZO3uN0JeF7XF1NzHTtrfqkyj06GUqpAmZZcN11Xfn1QADeGGP73fRgMGV33bJg/nwN8MOFBnmlClxdHRQX+4G+qAhOqIt31++8s2sgvBq2NF2jlOrsyXeOmNHFPfKG9uSVKnCO44+USR4xo/KHBnmlClxiHHxyCt51YdEi/6ca3jRdo1SBsyx4pd6lZbVD+eU2+7E6yxgk16dRw5MGeaUKnetSOS8e1deHWDknTCRipRpBqYYhTdcoVeiSi9NEIpyL09cISjXMaE9eqTzVs+57YsOWcpunW6yu7cnFaUIhxtfZhOt0wlO+0CCvVB5KLg8cCvk598p5tZj2CJO8EM8EwtxZYsXz7QdPY7XQ4J4vNMgrlYd6ZGBoWe1vEC9GMRHO8Rxejlhd+XYdF5+3NCevVJ5xXb9aZDDYlVcvv9yGUAgTCNJBiBewtR58gdCevFJ5JDlNU1QEX/uaX7ag0rKgMsy7Kx3qltm8HLUIxGDLFu3A5zsN8krlkeQ0DcC4cUlB3LJ41LF4Kb7CUywGN94IlZUa6PNZWtI1IrJcRD4Qka1J244WkedEZFv851HpOJZSqnepZq8mmz7d5eqrF1FR4U9l9TwtY5Dv0pWTfxi4uMe2bwNhY8wJQDh+XymVQVYfBSTb2lxisVq++tU7+Pd/r+XUU11KSjQvn+/Skq4xxrwoIhN6bL4MsOO3VwAO8M/pOJ5Sqne9DZRpbXXwvAgiMUaMiHDbbQ4nnmhpqibPZTInf4wxZnf89h7gmFQPEpG5wFyAcePGZbA5ShW2sjKbQCCE50UIBELMnGlTWprtVqlMG5ILr8YYIyKml31LgCUANTU1KR+jlBqAHlNeS0stqqrCtLY6lJXZlJZqF74QZDLIvy8ixxpjdovIscAHGTyWUipZzymv8QR9aamlwb3AZHIy1BpgTvz2HODJDB5LKZWs55RXHUJTsNI1hPJngAucJCK7ROQ64G7gAhHZBpwfv6+UGgr9jaVUBSNdo2tm9bKrNh2vr5SK65FnP6jSZEKKomOqMOmMV6WGix559i31YWrnWb2v4KRFxxRaoEyp4aNHnr1ltaNpd9UvDfJK5YC2NpedOxfR1tbHytk98uzll9uadlf90nSNUlnW1ubS2FjbOUmpqiqcephjjzx7pWURrtS0u+qbBnmlsixRbgBieF6E1lan97HsPfLsmnZX/dF0jVJZlig3AEECgRBlZXbnPteFRYv8n0oNhPbklcqy3soN9DJpVanDokFeqRyQqtxAqkmrGuTV4dJ0jVI5avp0l9mzF3Hqqa6OnlEDpj15pbItxbTVxAIf11wT4StfCTFiRBhLu/FqADTIK5VNvSTek0fcBIMRxo51AA3y6vBpukapLHFdcBY4mPaDp632NeJGqcOhPXmlMqitzU25SIfr+tmZ0yM2zxNiZCCCJCXedYEPlS4a5JXKkLY2l02bajEmgkiIqVPjM1ldl/fnOZwWsXGxqCXMP9c4zKy3uw2f0QU+VDpokFcqQ5qaHGKxCMFgjGg0wq9/7XDlWKC2ls8diHAhIWoJ8zIWa0+zmKnxXGWA5uSVSoNUM1M3b7bp6AgRjQaJRkPceafNzpUORCIETYxiIszAoaQE6uqy1nSV5/KiJ99b3lOpjIoPfdxSbqes615TY/H1r4c59VSHzZtt3njD4oVpUBcKQSRCoCjEyV+1WVenk5xU5gz7IH/IFfyUSqekoY8nB0KcFgvzW8/qVtfdceDiiy1+8AMLz4OSEjihzoI6v5Jk0Lap0+iuMmzYB/nDquCnVLok1RwoMhHOCzi8LBahEJSXdw19nzLF5dFHHfbssampseI9di0dqYbOsA/yifHEiZ68jidWQyKxgEfEH/p4Zb3NyBZ/cyL+n3SSy8KFtZSURDjmmBAVFWF0QpMaasM+yOt4YjWUOq//VNjwXD2t21dTdvzlVE6zqEx6XCgEp53mUFwcQUS/ZarsGfZBHnQ8sRoaXdd/2hFPIBDAjPcIxNYT/G0lL75odZafCYehocEmGAwBESDEmjU2NTWaqVFDKy+CvFJDwb/+0w54GAAvBgHwYu0sX+7w059a3UbXWJZFW1uYpiaHW26xaWqytC68GnI6Tl6pQ1RWZhOIBSEKEgXpAKIQaPcoa2nlS19axKRJbufoGvC/Zb700nyamqye5WmUGhLak1fqEJWWWlSN+A9al95IWUMUDLRWQ9GHwuduvBeKPTo6Qowa1f0Ca9I1Wq0Lr4Zc/gb5FDW6lUrFdWHbSpdzcRhfZ/f591I6bS6lgUoYuRKWL6f0zRg7ZwvBkhiIl7IscCJHr3+OKhvEGJPZA4hcDPwQCAI/Mcbc3dtja2pqTENDw+AP2kuNbo37qifXhfm2y7ORWkJEkJIQwXWHmDSP/0G1TS+nMTZPJ+SprBGRjcaYmlT7MtqTF5EgcD9wAbALeFVE1hhjmjN53FSLY7pYuiiyOojjwLQOhxARiogRG8BiqqWBSqpO1WG8KjdlOl1zJrDdGPMWgIisAi4DMhvkUyRBdVFklYptw/8LluNFhSiBbjXd+9Tj22JpOEypNT/TzVXqsGU6yB8H/DHp/i7gU8kPEJG5wFyAcePGpeeoKZKgNgdf/NL0zfCVrt+dhcuZwXlIzINAkMCP6g/tBbXXoIaJrF94NcYsAZaAn5NP2wtb3euD9Iz7kDJtr4aBVJdcoJegn5Q3bx3bcnA6xXEIRiNgPECgpeXQTiA6ZEYNE5kO8n8CPpl0f2x8W0b19p80Oe4vWtRLR0y79zlv5Uo4cACM8X93K1fCihUpTtjxs0HbpHYap3p4bwcIBEq6Xxi1bWJFIfAiUBSiudw+tJO/DplRw0Smg/yrwAkiMhE/uF8FfDmTB+xlYM1BUnbEDvXJKmtcF5Yv9wM8QFH8LzjlCTueUmmd4uEVA3h4XoQnnnA48US/IqSLxXwTZhoOvzU2kzdZ3V5r5co+4niPb4tK5aKMBnljTFREbgLW4g+hXG6M+X0mj3moqdKUHbFF3Z+8c6XDo45FeTm0tGiHLRc4jv/rAT+ffnuVw6SpNitC1sGZk/iZvKypnUCHhxcIcKA9xOLFNsIe1ecAAA5JSURBVDt2dP3+X4pZvGAsgjGYTNfJv6jIP6HEYnrOV8NXxnPyxphngWczfZyEvlKlPSe9WJbV+Z/WdWHbuzZXF4UIEiFWFGLOcpv1UfA8CAT8RR/0P3p2JX6/p7W7/NqrZWRDBNkS4pX6ME+3WJ2/70WLwLYtrHCYUsehalQ5T2xvYfFim61bLYLBrhN88t9LXZ3/z3Hg3Xdh6VK9tqqGOWNMzvw7/fTTTTps2GDMwoX+z+Rt54Y2mP9lpOkgaKIlIzsfsGGDMSNHGhMM+o955+sLzc+++6CZPXuhqajYYPzkgL9/4cK0NLGgpPp9DPb11l240HiB4EG/mOTf5ciRB/8NpNrXW/v6ei2lcgnQYHqJq1kfXZMJqVKlPSe9/M/x7Xz4hwWUVSzAcbrysC9hsaYCKitruSYW4eqrQ9x6a5g33rAoKvJ7d67bd49Or912Sb7MMWWKyw9/6DBlyuAmDFkWsMCG9Qd/ZesrXdfbtdLeUut6bVXlg7wM8qnYNswvtolEQrRVtPP7xR7eiOcJNK5n+vQwoaScbnW1QywWIRiMEQhEWLDA4Te/sVi+3P/6vmJF72kb14Xp0yEahWAQvvY1/+t/oQaInqskRaMRGhtTT/3v7+TYbcH2XiJwebmfWjMm9cjGw71WqtdW1XBXMEHesmCRY/H4yjBVkxfgjXiexGiL8eMdwmGrM15UVNg0NvpLCgaDIS680Gb7dr932F9+9t/+zQ/w4D/2gQf6PinkM9f1v/kEg/2vkrRkCdxwg3/9o7j44M83ecH2WCzEiBFhpk3rHoFdF+bN8z/3QADqk+Y1dTtBaNkBVUAKJshD8kIOC2hrXN9tXdjx45PjxcFLCh7q3Jf33jt4W8+TQiGkc5LTNEVFcOSRNsb4qyT1XIvXdf0Anxg1E4n4J8szz+z6jJIXbDcmwtKlDoGA1e3zS3xr8DwQf14T0P0EoQXEVKEpqCCfcCjrwvZcUjA5O1Be3rXwQ8/Zlfd9wuEWbF6Ol5oV6X5SKJSh+Mm5cWNg2TKLl14Kc/rpDl/7WvfP3HH8wJzsqaf8f4nPqKLCJhYLYUyEaDTExo32Qb393k7EyScIXWtVFZqCDPIwsHVhEwElZZCOR+8zIxHWF4e4bWqYEtuirKx7j/1wSp4M5x5/csAV8d/v1q0Wzc0Wu3fDggVd78m2/RRNJOLfP/VUl6oqh02bbN5804p/RhYjRoRZutRh40abHTuslPn2VBdKy8psAoFQt29uShWKgg3yA9VrkE7aUUSE+pkOzO+qYQ/+4w417ZPo8be3+/nl+++HuXO79mUz+B9KfrvnN5958/z34nnw3HPwwguwbl3XhU3H8WeXlpe7nHdeLZh2zOwgD337P7Bt/41Pm2YRCFjd3nvPzyLVhdJD+eamVL7SIH+Yeg3SKXZsWeLyyxsdfuPZ3FliUV/v54kTP/2LvC47d3YFn0QAbWiwaW+38Dw/MF5/vX+Yysreg39Ph3sy6O/xrgsNDS6VlbUkcuu95bd7vtYpp7isWePw9NM2zc0W7e1+UO85jHHnToe3324HPDAe36+6kQlUklhpKTmIH07qayDf3JTKBxrkD1Oih9rQ4FJd7VBRYQNWyjKXJ99Uy/+JRvg2IS44EObGG63OoX1+nrn7BcHjj69n+3Z/haFTTglRURFm61Y/MHke3HQTXHddV484sa2y8uDgdliVGnt5fPJjEvsvv9yhosIfXtpbfrvnaz33nEssVstFF0WYMcOfd9DcnDrgJhbL9oxHIApHveb1mtPSar9K9S+Q7QYMRxUVLlVVtcRid9DYWEtbm+vvsCyYP78z/1AU8ydeFRNhhjh4XveA1POC4N69q7vdnzLF6XbcxOiTQKD7tkQ6yHX96fyJXnTPQlu1tXDHHTBjBnz7XJcnPrWILUv8tqcKmMkS+yOvlUNHAOMFiEZDLF1q47qpHxuL+dUiN2504ieyGEVFEaqrHUIhmD3bZefORV2fH12LZU/8aRFV3wpQuqOk15xW4stTMKjVfpXqjfbkB+CQRmvYNlISwrRHIBii5ps2Jfd1T/MkXxCEEA0NlzNp0vrOESSbN9tAV1AvKfEnVk2d6qdvPM8PcIkFUJJ7z/X13bNHe/Z0lec9I+byf1701zSN/C7EFsLYtj+j1/P8IY89A6Ztw9lBl4ea53Hg1hh/qQ7w3c31PNZssXhxV3498dhgsGtkzUMP2dx7rz98sqgoxFln2dxwg9+7f/vtg9M+icWyd650ePJsmxOwSNVB1xmpSvVPg/wAHNJojXgEEseh2LaZaVmEZ/YMSP4FwaYmh1tusWlqspgypZL58x0WLrQ7UxqBAPzDP3TNnN2ypWvIYUeHf3/Tpq4gflq7y4mrHV6pt9m0CU7e43Db0zbG+K9n01XewRChZbVDSaXVWb7XGDhyS/ekumXBimsdRjwY4SPNHqOahb/DH4ieqnzAtdfCgw/6r7Vli8WWLWEuvdS/9mDbFjt3LuLttxMnygPs2bOy24nSxaJ2RXwWch+TyXRGqlJ90yA/AIc8WiPF6lSpRn689JJFU5Pf821qsti+3eKss6CxMVEaDcaN63ru6tXdX2PZsq7HnkW8OuPzEbx1QSZ7gnhRfmVC3EI9o2nhz5QTIYQhQgchyi+3edrp6nmfEXU5+aZafyGNpAT9+DobVvjfTjq8EA424D+kvDxR+dFvZ11d94U8amosxo/vevNlZTYiQYyJAYY9ex5izJg6mputzgqQmm9XavA0yA9QOkdr9DZiJzlIJqdPLr8cfv3rrvuf+ARs3OjfnoFDiUQQLwaehwBBDCHauZ8bCWCgOMQqq54jD7Qw6TqbyrkW+13/OO3tcC6JJfF6RNikbyc7ym2qN1lU46eP5s07+KJtX6mU0lKLMWOuZffuBwGDMVGamhwuusjqnCUbDPqP1Xy7UgOnQT4H9BYQewuSiSGTq1f7Ab+yEtau9QP0erExgRCxaIQOEwQEjygSCFDkxQjggRdh9sUt/kXipDbU1/ujdZyozQETYmQggvSMsPFgXwn8OL6pt6UU+0uljBlTx/vvr+hMe23ebHe+DvjF3caN03y7UoPSWw3ibPxLVz35QvTgg8YUFxsTCPg18V+ZudCcG9pgpgU2mDuKFprttz/Yb3H0hQv93WDMtMAGs+7CQysCP5i6662tG8w77yw0ra0btH67UgNEodWTL0QtLV1j51+KWYTPtFh0e+KbgMUkC5hZ2edQlOS00Wshi5IFFimHtfQwmFEuyWkvHS2jVPqJSQypyAE1NTWmoaEh283IOYcyczVdhc+yXTJBKXX4RGSjMaYm1T7tyee4Qw3e6eoF65BEpfKLBvkcdzhT9zVAK6V60rIGOU6n7iulBkN78jlOL0YqpQZDg/wwoGkYpdRAabpGKaXy2KCCvIhcKSK/FxFPRGp67JsvIttF5E0RuWhwzVRKKTUQg03XbAW+ADyYvFFEKoCrgFOATwDPi8iJxq9GpZRSaogMqidvjHndGPNmil2XAauMMe3GmLeB7cCZgzmWUkqpw5epnPxxwB+T7u+KbzuIiMwVkQYRadi7d2+GmqOUUoWp33SNiDwPjEmx67vGmCcH2wBjzBJgCfhlDQb7ekoppbr0G+SNMecP4HX/BHwy6f7Y+LY+bdy48c8isnMAxwP4GPDnAT53uNL3XBj0PReGwbzn8b3tyNQ4+TXAoyLyA/wLrycAv+vvScaY0QM9oIg09FagJ1/pey4M+p4LQ6be82CHUH5eRHbhF6R9RkTWAhhjfg88BjQDvwJu1JE1Sik19AbVkzfG/AL4RS/77gLuGszrK6WUGpx8mvG6JNsNyAJ9z4VB33NhyMh7zqlFQ5RSSqVXPvXklVJK9aBBXiml8tiwD/IicnG8CNp2Efl2ttuTaSLySRFZJyLN8eJwt2S7TUNFRIIisklEns52W4aKiJSJyOMi8oaIvC4ieV90WkS+Gf/b3ioiPxOREdluU7qJyHIR+UBEtiZtO1pEnhORbfGfR6XjWMM6yItIELgf+AxQAcyKF0fLZ1HgVmNMBXAWcGMBvOeEW4DXs92IIfZD4FfGmJOBKvL8/YvIccDNQI0x5lQgiF/sMN88DFzcY9u3gbAx5gQgHL8/aMM6yOMXPdtujHnLGBMBVuEXR8tbxpjdxpjX4rf34f+nT1kXKJ+IyFjgEuAn2W7LUBGRUmA6sAzAGBMxxrRmt1VDoggYKSJFwEeA97LcnrQzxrwI/KXH5suAFfHbK4CZ6TjWcA/yh1wILR+JyARgKvBKdlsyJOqB2wEv2w0ZQhOBvcBD8TTVT0TkiGw3KpOMMX8CFgPvAruBNmPMr7PbqiFzjDFmd/z2HuCYdLzocA/yBUtEjgRWA/OMMR9muz2ZJCKfBT4wxmzMdluGWBFwGvBjY8xU4H9J01f4XBXPQ1+Gf4L7BHCEiMzObquGnvHHtqdlfPtwD/IDKoQ23IlIMX6Af8QY89/Zbs8QmAZcKiLv4KfkzhORn2a3SUNiF7DLGJP4pvY4ftDPZ+cDbxtj9hpjOoD/Bj6d5TYNlfdF5FiA+M8P0vGiwz3IvwqcICITRSSEf4FmTZbblFEiIvg52teNMT/IdnuGgjFmvjFmrDFmAv7v+DfGmLzv3Rlj9gB/FJGT4ptq8etB5bN3gbNE5CPxv/Va8vxic5I1wJz47TnAoEu5Q+aqUA4JY0xURG4C1uJfhV8eL46Wz6YBXwG2iMjm+LbvGGOezWKbVOZ8A3gk3ol5C/hqltuTUcaYV0TkceA1/JFkm8jDEgci8jPABj4WL/L4PeBu4DERuQ7YCXwxLcfSsgZKKZW/hnu6RimlVB80yCulVB7TIK+UUnlMg7xSSuUxDfJKKZXHNMgrpVQe0yCvlFJ57P8Drib3x2wLgGYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JggfIuHp4PCy",
        "colab_type": "text"
      },
      "source": [
        "## Design a model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nty9IWi-4QhR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We'll use Keras to create a simple model architecture\n",
        "from tensorflow.keras import layers\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "# First layer takes a scalar input and feeds it through 16 \"neurons\". The\n",
        "# neurons decide whether to activate based on the 'relu' activation function.\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(1,)))\n",
        "\n",
        "# The new second layer may help the network learn more complex representations\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "\n",
        "# Final layer is a single neuron, since we want to output a single value\n",
        "model.add(layers.Dense(1))\n",
        "\n",
        "# Compile the model using a standard optimizer and loss function for regression\n",
        "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMeLOUmx4VY7",
        "colab_type": "text"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJiV9Aee4ZTb",
        "colab_type": "code",
        "outputId": "c87a56cf-2cad-475b-a7aa-3f17a60f8b1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train the model on our training data while validating on our validation set\n",
        "model.fit(x_train, y_train, epochs=1000, batch_size=16,\n",
        "          validation_data=(x_validate, y_validate))\n",
        "\n",
        "print(\"Done!\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 366.2199 - mae: 12.4782 - val_loss: 435.9289 - val_mae: 14.8505\n",
            "Epoch 2/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 336.0269 - mae: 12.3604 - val_loss: 424.9843 - val_mae: 14.6756\n",
            "Epoch 3/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 323.6185 - mae: 12.2697 - val_loss: 415.6217 - val_mae: 14.5223\n",
            "Epoch 4/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 339.8432 - mae: 12.2058 - val_loss: 407.3253 - val_mae: 14.3820\n",
            "Epoch 5/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 317.5516 - mae: 12.1235 - val_loss: 399.1044 - val_mae: 14.2375\n",
            "Epoch 6/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 349.5450 - mae: 12.0569 - val_loss: 393.0375 - val_mae: 14.1354\n",
            "Epoch 7/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 299.9836 - mae: 12.0096 - val_loss: 388.1806 - val_mae: 14.0535\n",
            "Epoch 8/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 338.7892 - mae: 11.9674 - val_loss: 381.9288 - val_mae: 13.9437\n",
            "Epoch 9/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 295.9004 - mae: 11.9184 - val_loss: 376.6671 - val_mae: 13.8518\n",
            "Epoch 10/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 298.9395 - mae: 11.8829 - val_loss: 370.9106 - val_mae: 13.7547\n",
            "Epoch 11/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 289.2462 - mae: 11.8239 - val_loss: 365.0207 - val_mae: 13.6560\n",
            "Epoch 12/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 318.1912 - mae: 11.7763 - val_loss: 357.9766 - val_mae: 13.5381\n",
            "Epoch 13/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 298.9777 - mae: 11.7109 - val_loss: 351.2637 - val_mae: 13.4252\n",
            "Epoch 14/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 322.1453 - mae: 11.6563 - val_loss: 343.8009 - val_mae: 13.3047\n",
            "Epoch 15/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 276.2188 - mae: 11.6023 - val_loss: 337.5165 - val_mae: 13.2108\n",
            "Epoch 16/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 267.2427 - mae: 11.5594 - val_loss: 331.2746 - val_mae: 13.1160\n",
            "Epoch 17/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 288.4017 - mae: 11.5005 - val_loss: 323.2626 - val_mae: 13.0056\n",
            "Epoch 18/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 267.5067 - mae: 11.4438 - val_loss: 316.3098 - val_mae: 12.9069\n",
            "Epoch 19/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 247.3915 - mae: 11.3703 - val_loss: 308.6457 - val_mae: 12.7990\n",
            "Epoch 20/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 276.0335 - mae: 11.3114 - val_loss: 299.8725 - val_mae: 12.6708\n",
            "Epoch 21/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 242.5849 - mae: 11.2448 - val_loss: 292.0771 - val_mae: 12.5557\n",
            "Epoch 22/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 232.7239 - mae: 11.1849 - val_loss: 283.7290 - val_mae: 12.4308\n",
            "Epoch 23/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 236.2990 - mae: 11.1194 - val_loss: 274.8579 - val_mae: 12.2900\n",
            "Epoch 24/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 218.0259 - mae: 11.0683 - val_loss: 266.7868 - val_mae: 12.1692\n",
            "Epoch 25/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 244.9874 - mae: 11.0094 - val_loss: 257.3165 - val_mae: 12.0330\n",
            "Epoch 26/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 208.5882 - mae: 10.9622 - val_loss: 250.0842 - val_mae: 11.9336\n",
            "Epoch 27/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 212.3657 - mae: 10.9088 - val_loss: 241.9080 - val_mae: 11.8201\n",
            "Epoch 28/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 209.6953 - mae: 10.8502 - val_loss: 233.2360 - val_mae: 11.6995\n",
            "Epoch 29/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 201.2203 - mae: 10.8040 - val_loss: 225.0183 - val_mae: 11.5784\n",
            "Epoch 30/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 198.6308 - mae: 10.7410 - val_loss: 215.8609 - val_mae: 11.4348\n",
            "Epoch 31/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 184.5993 - mae: 10.6766 - val_loss: 207.5303 - val_mae: 11.3103\n",
            "Epoch 32/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 183.3493 - mae: 10.6176 - val_loss: 198.9829 - val_mae: 11.1880\n",
            "Epoch 33/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 178.9180 - mae: 10.5576 - val_loss: 191.5426 - val_mae: 11.0720\n",
            "Epoch 34/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 169.0586 - mae: 10.5092 - val_loss: 184.1933 - val_mae: 10.9519\n",
            "Epoch 35/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 176.9594 - mae: 10.4361 - val_loss: 175.5218 - val_mae: 10.8099\n",
            "Epoch 36/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 160.1272 - mae: 10.3765 - val_loss: 170.0358 - val_mae: 10.7234\n",
            "Epoch 37/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 163.3272 - mae: 10.3127 - val_loss: 163.6644 - val_mae: 10.6223\n",
            "Epoch 38/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 157.5790 - mae: 10.2689 - val_loss: 158.0201 - val_mae: 10.5237\n",
            "Epoch 39/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 153.5182 - mae: 10.2226 - val_loss: 152.1963 - val_mae: 10.4156\n",
            "Epoch 40/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 149.5514 - mae: 10.1904 - val_loss: 147.4802 - val_mae: 10.3191\n",
            "Epoch 41/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 148.8940 - mae: 10.1427 - val_loss: 142.3124 - val_mae: 10.2054\n",
            "Epoch 42/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 139.7831 - mae: 10.1277 - val_loss: 138.6962 - val_mae: 10.1158\n",
            "Epoch 43/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 147.3791 - mae: 10.1086 - val_loss: 135.3339 - val_mae: 10.0278\n",
            "Epoch 44/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 142.1572 - mae: 10.0942 - val_loss: 132.9579 - val_mae: 9.9576\n",
            "Epoch 45/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 137.5131 - mae: 10.0766 - val_loss: 130.3496 - val_mae: 9.8746\n",
            "Epoch 46/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 132.8475 - mae: 10.0569 - val_loss: 128.9543 - val_mae: 9.8282\n",
            "Epoch 47/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 130.4687 - mae: 10.0262 - val_loss: 127.3543 - val_mae: 9.7716\n",
            "Epoch 48/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 137.6133 - mae: 10.0149 - val_loss: 124.9985 - val_mae: 9.6812\n",
            "Epoch 49/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 133.8002 - mae: 10.0003 - val_loss: 123.2201 - val_mae: 9.6090\n",
            "Epoch 50/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 132.5695 - mae: 10.0203 - val_loss: 121.8957 - val_mae: 9.5497\n",
            "Epoch 51/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 129.4144 - mae: 9.9812 - val_loss: 120.6365 - val_mae: 9.4868\n",
            "Epoch 52/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 129.2950 - mae: 9.9797 - val_loss: 119.4933 - val_mae: 9.4333\n",
            "Epoch 53/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 130.5842 - mae: 9.9842 - val_loss: 118.5207 - val_mae: 9.3910\n",
            "Epoch 54/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 129.0274 - mae: 9.9797 - val_loss: 117.6162 - val_mae: 9.3492\n",
            "Epoch 55/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 125.0637 - mae: 9.9843 - val_loss: 117.1659 - val_mae: 9.3289\n",
            "Epoch 56/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 129.8881 - mae: 9.9601 - val_loss: 116.7140 - val_mae: 9.3083\n",
            "Epoch 57/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 123.4149 - mae: 9.9584 - val_loss: 116.2855 - val_mae: 9.2886\n",
            "Epoch 58/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 126.4678 - mae: 9.9286 - val_loss: 115.7196 - val_mae: 9.2615\n",
            "Epoch 59/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 132.0760 - mae: 9.8889 - val_loss: 114.7736 - val_mae: 9.2110\n",
            "Epoch 60/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 123.0061 - mae: 9.9047 - val_loss: 114.6789 - val_mae: 9.2117\n",
            "Epoch 61/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 125.9737 - mae: 9.8482 - val_loss: 114.1174 - val_mae: 9.1833\n",
            "Epoch 62/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 124.2184 - mae: 9.8281 - val_loss: 113.7626 - val_mae: 9.1672\n",
            "Epoch 63/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 125.5427 - mae: 9.8006 - val_loss: 113.3668 - val_mae: 9.1484\n",
            "Epoch 64/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 122.8115 - mae: 9.7795 - val_loss: 112.5844 - val_mae: 9.1028\n",
            "Epoch 65/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 117.4240 - mae: 9.7790 - val_loss: 112.1443 - val_mae: 9.0827\n",
            "Epoch 66/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 120.4697 - mae: 9.7731 - val_loss: 111.9815 - val_mae: 9.0808\n",
            "Epoch 67/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 120.7797 - mae: 9.7199 - val_loss: 111.4099 - val_mae: 9.0511\n",
            "Epoch 68/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 122.8110 - mae: 9.7025 - val_loss: 110.7993 - val_mae: 9.0186\n",
            "Epoch 69/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 119.7682 - mae: 9.6776 - val_loss: 110.4182 - val_mae: 9.0025\n",
            "Epoch 70/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 119.4053 - mae: 9.6411 - val_loss: 109.4903 - val_mae: 8.9430\n",
            "Epoch 71/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 116.9148 - mae: 9.6674 - val_loss: 109.5243 - val_mae: 8.9602\n",
            "Epoch 72/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 114.9818 - mae: 9.6047 - val_loss: 109.2150 - val_mae: 8.9474\n",
            "Epoch 73/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 116.1620 - mae: 9.5897 - val_loss: 108.9405 - val_mae: 8.9362\n",
            "Epoch 74/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 119.3321 - mae: 9.5445 - val_loss: 108.4561 - val_mae: 8.9115\n",
            "Epoch 75/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 119.3258 - mae: 9.5257 - val_loss: 107.8350 - val_mae: 8.8777\n",
            "Epoch 76/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 113.2341 - mae: 9.5032 - val_loss: 107.3480 - val_mae: 8.8527\n",
            "Epoch 77/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 115.8698 - mae: 9.4940 - val_loss: 107.0118 - val_mae: 8.8376\n",
            "Epoch 78/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 113.9126 - mae: 9.4368 - val_loss: 106.6212 - val_mae: 8.8188\n",
            "Epoch 79/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 118.9804 - mae: 9.3958 - val_loss: 105.7600 - val_mae: 8.7663\n",
            "Epoch 80/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 112.1796 - mae: 9.4037 - val_loss: 105.5245 - val_mae: 8.7606\n",
            "Epoch 81/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 115.4381 - mae: 9.3378 - val_loss: 104.6258 - val_mae: 8.6998\n",
            "Epoch 82/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 112.6597 - mae: 9.3757 - val_loss: 104.5953 - val_mae: 8.7118\n",
            "Epoch 83/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 111.8621 - mae: 9.3046 - val_loss: 104.0770 - val_mae: 8.6830\n",
            "Epoch 84/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 117.0582 - mae: 9.2879 - val_loss: 103.4717 - val_mae: 8.6483\n",
            "Epoch 85/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 108.9785 - mae: 9.2528 - val_loss: 103.0981 - val_mae: 8.6324\n",
            "Epoch 86/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 110.0096 - mae: 9.2222 - val_loss: 102.7008 - val_mae: 8.6146\n",
            "Epoch 87/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 109.8736 - mae: 9.1809 - val_loss: 101.8825 - val_mae: 8.5594\n",
            "Epoch 88/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 105.5723 - mae: 9.1649 - val_loss: 101.4564 - val_mae: 8.5399\n",
            "Epoch 89/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 109.6389 - mae: 9.1436 - val_loss: 100.9323 - val_mae: 8.5120\n",
            "Epoch 90/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 108.9233 - mae: 9.1256 - val_loss: 100.9309 - val_mae: 8.5273\n",
            "Epoch 91/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 109.1146 - mae: 9.0540 - val_loss: 100.3017 - val_mae: 8.4906\n",
            "Epoch 92/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 107.7414 - mae: 9.0421 - val_loss: 100.0033 - val_mae: 8.4801\n",
            "Epoch 93/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 108.1590 - mae: 9.0052 - val_loss: 99.6385 - val_mae: 8.4634\n",
            "Epoch 94/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 105.9622 - mae: 8.9634 - val_loss: 99.0508 - val_mae: 8.4315\n",
            "Epoch 95/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 100.8832 - mae: 8.9409 - val_loss: 98.4218 - val_mae: 8.3948\n",
            "Epoch 96/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 104.9702 - mae: 8.9165 - val_loss: 98.0354 - val_mae: 8.3768\n",
            "Epoch 97/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 105.9508 - mae: 8.8696 - val_loss: 97.0469 - val_mae: 8.3096\n",
            "Epoch 98/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 103.9460 - mae: 8.8458 - val_loss: 96.4258 - val_mae: 8.2724\n",
            "Epoch 99/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 101.7717 - mae: 8.8193 - val_loss: 96.0448 - val_mae: 8.2576\n",
            "Epoch 100/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 106.0261 - mae: 8.7961 - val_loss: 95.3704 - val_mae: 8.2119\n",
            "Epoch 101/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 104.2110 - mae: 8.7560 - val_loss: 94.9187 - val_mae: 8.1921\n",
            "Epoch 102/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 103.3609 - mae: 8.7224 - val_loss: 94.1454 - val_mae: 8.1429\n",
            "Epoch 103/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 101.1656 - mae: 8.7190 - val_loss: 93.6398 - val_mae: 8.1175\n",
            "Epoch 104/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 100.1362 - mae: 8.6820 - val_loss: 93.0626 - val_mae: 8.0874\n",
            "Epoch 105/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 99.7532 - mae: 8.6820 - val_loss: 92.8492 - val_mae: 8.0808\n",
            "Epoch 106/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 97.4468 - mae: 8.6380 - val_loss: 92.6965 - val_mae: 8.0826\n",
            "Epoch 107/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 97.8243 - mae: 8.5701 - val_loss: 92.2310 - val_mae: 8.0574\n",
            "Epoch 108/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 94.5929 - mae: 8.5397 - val_loss: 91.7448 - val_mae: 8.0314\n",
            "Epoch 109/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 100.3222 - mae: 8.4793 - val_loss: 90.7736 - val_mae: 7.9708\n",
            "Epoch 110/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 98.5115 - mae: 8.4775 - val_loss: 90.0880 - val_mae: 7.9349\n",
            "Epoch 111/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 95.9313 - mae: 8.4673 - val_loss: 89.7742 - val_mae: 7.9178\n",
            "Epoch 112/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 98.6192 - mae: 8.3942 - val_loss: 89.1348 - val_mae: 7.8861\n",
            "Epoch 113/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 94.6798 - mae: 8.3947 - val_loss: 88.8427 - val_mae: 7.8697\n",
            "Epoch 114/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 94.9404 - mae: 8.3433 - val_loss: 88.2128 - val_mae: 7.8381\n",
            "Epoch 115/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 94.1419 - mae: 8.3165 - val_loss: 87.6702 - val_mae: 7.8100\n",
            "Epoch 116/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 90.2899 - mae: 8.2617 - val_loss: 86.9574 - val_mae: 7.7706\n",
            "Epoch 117/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 97.5905 - mae: 8.2338 - val_loss: 86.4533 - val_mae: 7.7472\n",
            "Epoch 118/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 90.0029 - mae: 8.2253 - val_loss: 85.9771 - val_mae: 7.7216\n",
            "Epoch 119/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 89.0633 - mae: 8.1562 - val_loss: 85.4881 - val_mae: 7.6962\n",
            "Epoch 120/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 88.0433 - mae: 8.1057 - val_loss: 84.8736 - val_mae: 7.6636\n",
            "Epoch 121/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 90.3815 - mae: 8.0940 - val_loss: 84.4199 - val_mae: 7.6399\n",
            "Epoch 122/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 86.2467 - mae: 8.0350 - val_loss: 83.8506 - val_mae: 7.6099\n",
            "Epoch 123/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 87.8185 - mae: 8.0170 - val_loss: 83.2293 - val_mae: 7.5769\n",
            "Epoch 124/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 86.5641 - mae: 7.9704 - val_loss: 82.5867 - val_mae: 7.5426\n",
            "Epoch 125/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 85.6024 - mae: 7.9399 - val_loss: 82.3448 - val_mae: 7.5264\n",
            "Epoch 126/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 85.7482 - mae: 7.8577 - val_loss: 81.6036 - val_mae: 7.4893\n",
            "Epoch 127/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 85.4497 - mae: 7.8119 - val_loss: 80.7787 - val_mae: 7.4449\n",
            "Epoch 128/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 84.7282 - mae: 7.7994 - val_loss: 80.2678 - val_mae: 7.4178\n",
            "Epoch 129/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 80.9092 - mae: 7.7332 - val_loss: 79.5787 - val_mae: 7.3799\n",
            "Epoch 130/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 80.2533 - mae: 7.7090 - val_loss: 79.0125 - val_mae: 7.3497\n",
            "Epoch 131/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 85.7360 - mae: 7.6652 - val_loss: 78.2498 - val_mae: 7.3198\n",
            "Epoch 132/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 80.1909 - mae: 7.6481 - val_loss: 77.6538 - val_mae: 7.2856\n",
            "Epoch 133/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 77.8475 - mae: 7.5713 - val_loss: 76.9965 - val_mae: 7.2585\n",
            "Epoch 134/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 77.8325 - mae: 7.5470 - val_loss: 76.3641 - val_mae: 7.2271\n",
            "Epoch 135/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 76.5409 - mae: 7.4952 - val_loss: 75.8558 - val_mae: 7.1911\n",
            "Epoch 136/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 77.0518 - mae: 7.4751 - val_loss: 75.4225 - val_mae: 7.1546\n",
            "Epoch 137/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 77.8694 - mae: 7.3987 - val_loss: 74.6821 - val_mae: 7.1302\n",
            "Epoch 138/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 75.1906 - mae: 7.3539 - val_loss: 73.9862 - val_mae: 7.1060\n",
            "Epoch 139/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 75.0349 - mae: 7.3121 - val_loss: 73.3486 - val_mae: 7.0720\n",
            "Epoch 140/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 75.8166 - mae: 7.2720 - val_loss: 72.7288 - val_mae: 7.0496\n",
            "Epoch 141/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 76.2649 - mae: 7.2092 - val_loss: 72.2885 - val_mae: 7.0328\n",
            "Epoch 142/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 71.1670 - mae: 7.2236 - val_loss: 71.7513 - val_mae: 6.9751\n",
            "Epoch 143/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 72.7958 - mae: 7.1340 - val_loss: 71.0817 - val_mae: 6.9549\n",
            "Epoch 144/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 71.0246 - mae: 7.1275 - val_loss: 70.5916 - val_mae: 6.9160\n",
            "Epoch 145/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 68.4610 - mae: 7.0714 - val_loss: 70.0479 - val_mae: 6.8761\n",
            "Epoch 146/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 70.6930 - mae: 7.0121 - val_loss: 69.1792 - val_mae: 6.8515\n",
            "Epoch 147/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 67.3978 - mae: 6.9687 - val_loss: 68.5606 - val_mae: 6.8165\n",
            "Epoch 148/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 71.7198 - mae: 6.9453 - val_loss: 67.8756 - val_mae: 6.7878\n",
            "Epoch 149/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 68.4075 - mae: 6.9015 - val_loss: 67.2937 - val_mae: 6.7600\n",
            "Epoch 150/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 66.7310 - mae: 6.8782 - val_loss: 66.7375 - val_mae: 6.7198\n",
            "Epoch 151/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 67.3882 - mae: 6.8330 - val_loss: 66.2156 - val_mae: 6.6828\n",
            "Epoch 152/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 66.3057 - mae: 6.7372 - val_loss: 65.5376 - val_mae: 6.6628\n",
            "Epoch 153/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 63.5220 - mae: 6.7612 - val_loss: 65.0593 - val_mae: 6.6146\n",
            "Epoch 154/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 63.9867 - mae: 6.6663 - val_loss: 64.4107 - val_mae: 6.5878\n",
            "Epoch 155/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 61.9310 - mae: 6.6456 - val_loss: 63.8840 - val_mae: 6.5499\n",
            "Epoch 156/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 66.8307 - mae: 6.5949 - val_loss: 63.2489 - val_mae: 6.5266\n",
            "Epoch 157/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 63.0090 - mae: 6.5535 - val_loss: 62.7008 - val_mae: 6.4903\n",
            "Epoch 158/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 62.8298 - mae: 6.5013 - val_loss: 62.1082 - val_mae: 6.4554\n",
            "Epoch 159/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 60.4011 - mae: 6.4811 - val_loss: 61.7092 - val_mae: 6.4083\n",
            "Epoch 160/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 61.8450 - mae: 6.3731 - val_loss: 60.9645 - val_mae: 6.3793\n",
            "Epoch 161/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 61.3055 - mae: 6.3322 - val_loss: 60.3349 - val_mae: 6.3567\n",
            "Epoch 162/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 57.1253 - mae: 6.3107 - val_loss: 59.7648 - val_mae: 6.3225\n",
            "Epoch 163/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 57.2308 - mae: 6.2841 - val_loss: 59.3071 - val_mae: 6.2764\n",
            "Epoch 164/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 55.0252 - mae: 6.1572 - val_loss: 58.6321 - val_mae: 6.2569\n",
            "Epoch 165/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 55.1039 - mae: 6.1675 - val_loss: 57.9489 - val_mae: 6.2270\n",
            "Epoch 166/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 55.9136 - mae: 6.1445 - val_loss: 57.2870 - val_mae: 6.1935\n",
            "Epoch 167/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 53.3398 - mae: 6.0940 - val_loss: 56.7304 - val_mae: 6.1501\n",
            "Epoch 168/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 54.2218 - mae: 6.0377 - val_loss: 56.0821 - val_mae: 6.1210\n",
            "Epoch 169/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 54.4554 - mae: 5.9899 - val_loss: 55.4315 - val_mae: 6.0851\n",
            "Epoch 170/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 51.7014 - mae: 5.9456 - val_loss: 54.8475 - val_mae: 6.0478\n",
            "Epoch 171/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 50.7103 - mae: 5.8873 - val_loss: 54.2074 - val_mae: 6.0129\n",
            "Epoch 172/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 50.4346 - mae: 5.8420 - val_loss: 53.5958 - val_mae: 5.9857\n",
            "Epoch 173/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 50.0111 - mae: 5.7841 - val_loss: 52.9169 - val_mae: 5.9536\n",
            "Epoch 174/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 51.1152 - mae: 5.7814 - val_loss: 52.4268 - val_mae: 5.9041\n",
            "Epoch 175/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 52.6503 - mae: 5.6684 - val_loss: 51.8849 - val_mae: 5.9083\n",
            "Epoch 176/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 47.6103 - mae: 5.6827 - val_loss: 51.3454 - val_mae: 5.8402\n",
            "Epoch 177/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 46.1653 - mae: 5.6120 - val_loss: 50.7875 - val_mae: 5.8062\n",
            "Epoch 178/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 47.1051 - mae: 5.5528 - val_loss: 50.1318 - val_mae: 5.7667\n",
            "Epoch 179/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 45.8937 - mae: 5.5210 - val_loss: 49.5401 - val_mae: 5.7252\n",
            "Epoch 180/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 45.3749 - mae: 5.4332 - val_loss: 48.7871 - val_mae: 5.6983\n",
            "Epoch 181/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 45.1451 - mae: 5.4258 - val_loss: 48.2445 - val_mae: 5.6514\n",
            "Epoch 182/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 44.3604 - mae: 5.3490 - val_loss: 47.6704 - val_mae: 5.6168\n",
            "Epoch 183/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 45.2220 - mae: 5.3249 - val_loss: 47.0946 - val_mae: 5.6023\n",
            "Epoch 184/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 42.2097 - mae: 5.2859 - val_loss: 46.5514 - val_mae: 5.5529\n",
            "Epoch 185/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 44.0468 - mae: 5.2049 - val_loss: 45.9596 - val_mae: 5.5773\n",
            "Epoch 186/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 41.1373 - mae: 5.2081 - val_loss: 45.3435 - val_mae: 5.5028\n",
            "Epoch 187/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 41.1318 - mae: 5.1500 - val_loss: 44.6724 - val_mae: 5.4469\n",
            "Epoch 188/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 40.0648 - mae: 5.0692 - val_loss: 43.9648 - val_mae: 5.4059\n",
            "Epoch 189/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 40.0639 - mae: 5.0808 - val_loss: 43.4646 - val_mae: 5.3404\n",
            "Epoch 190/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 38.2097 - mae: 4.9603 - val_loss: 42.8147 - val_mae: 5.3322\n",
            "Epoch 191/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 37.6342 - mae: 4.9629 - val_loss: 42.2167 - val_mae: 5.2827\n",
            "Epoch 192/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 38.3806 - mae: 4.8951 - val_loss: 41.5557 - val_mae: 5.2368\n",
            "Epoch 193/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 38.4217 - mae: 4.8227 - val_loss: 40.9932 - val_mae: 5.2763\n",
            "Epoch 194/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 37.0751 - mae: 4.8259 - val_loss: 40.4687 - val_mae: 5.2609\n",
            "Epoch 195/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 37.4918 - mae: 4.7773 - val_loss: 39.7311 - val_mae: 5.1878\n",
            "Epoch 196/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 35.8005 - mae: 4.7104 - val_loss: 39.1742 - val_mae: 5.1887\n",
            "Epoch 197/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 34.8799 - mae: 4.7044 - val_loss: 38.4066 - val_mae: 5.0966\n",
            "Epoch 198/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 35.5274 - mae: 4.6343 - val_loss: 37.7564 - val_mae: 5.0198\n",
            "Epoch 199/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 34.6207 - mae: 4.5783 - val_loss: 37.2553 - val_mae: 4.9856\n",
            "Epoch 200/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 33.9555 - mae: 4.5086 - val_loss: 36.7683 - val_mae: 5.0145\n",
            "Epoch 201/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 35.5062 - mae: 4.4867 - val_loss: 36.0831 - val_mae: 4.9358\n",
            "Epoch 202/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 33.0141 - mae: 4.4233 - val_loss: 35.6846 - val_mae: 4.9560\n",
            "Epoch 203/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 30.9171 - mae: 4.4214 - val_loss: 34.9681 - val_mae: 4.8285\n",
            "Epoch 204/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 30.7223 - mae: 4.3350 - val_loss: 34.4150 - val_mae: 4.8139\n",
            "Epoch 205/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 32.0535 - mae: 4.2786 - val_loss: 33.9897 - val_mae: 4.8415\n",
            "Epoch 206/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 29.9173 - mae: 4.2929 - val_loss: 33.3459 - val_mae: 4.7778\n",
            "Epoch 207/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 33.5192 - mae: 4.2062 - val_loss: 33.1692 - val_mae: 4.8286\n",
            "Epoch 208/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 31.3582 - mae: 4.2207 - val_loss: 32.6464 - val_mae: 4.7880\n",
            "Epoch 209/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 28.5109 - mae: 4.1853 - val_loss: 32.1001 - val_mae: 4.7317\n",
            "Epoch 210/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 28.3282 - mae: 4.1495 - val_loss: 31.2666 - val_mae: 4.5553\n",
            "Epoch 211/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 28.8908 - mae: 4.0515 - val_loss: 30.8495 - val_mae: 4.5859\n",
            "Epoch 212/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 28.2449 - mae: 4.0514 - val_loss: 30.2674 - val_mae: 4.5057\n",
            "Epoch 213/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 26.0242 - mae: 3.9651 - val_loss: 29.8958 - val_mae: 4.5074\n",
            "Epoch 214/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 27.1826 - mae: 3.9826 - val_loss: 29.2953 - val_mae: 4.4063\n",
            "Epoch 215/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 26.3560 - mae: 3.8804 - val_loss: 29.1505 - val_mae: 4.4854\n",
            "Epoch 216/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 25.2204 - mae: 3.9080 - val_loss: 28.5625 - val_mae: 4.4109\n",
            "Epoch 217/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 24.5900 - mae: 3.8605 - val_loss: 28.1399 - val_mae: 4.3764\n",
            "Epoch 218/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 25.3709 - mae: 3.8274 - val_loss: 27.4799 - val_mae: 4.2725\n",
            "Epoch 219/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 25.0536 - mae: 3.7689 - val_loss: 27.0629 - val_mae: 4.2953\n",
            "Epoch 220/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 22.9321 - mae: 3.7315 - val_loss: 26.5102 - val_mae: 4.2222\n",
            "Epoch 221/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 23.8435 - mae: 3.7226 - val_loss: 25.9102 - val_mae: 4.1246\n",
            "Epoch 222/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 22.5991 - mae: 3.6449 - val_loss: 25.4333 - val_mae: 4.0811\n",
            "Epoch 223/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 23.1538 - mae: 3.6259 - val_loss: 24.9708 - val_mae: 4.0125\n",
            "Epoch 224/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 21.4916 - mae: 3.5342 - val_loss: 24.5986 - val_mae: 4.0156\n",
            "Epoch 225/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 20.9701 - mae: 3.5300 - val_loss: 24.2510 - val_mae: 3.9913\n",
            "Epoch 226/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 21.2156 - mae: 3.5307 - val_loss: 23.7757 - val_mae: 3.8850\n",
            "Epoch 227/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 20.4995 - mae: 3.4589 - val_loss: 23.3392 - val_mae: 3.8641\n",
            "Epoch 228/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 20.7190 - mae: 3.3833 - val_loss: 23.0855 - val_mae: 3.9266\n",
            "Epoch 229/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 20.7975 - mae: 3.3631 - val_loss: 22.8131 - val_mae: 3.9226\n",
            "Epoch 230/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 19.5540 - mae: 3.3301 - val_loss: 23.0443 - val_mae: 3.9817\n",
            "Epoch 231/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 18.7201 - mae: 3.3405 - val_loss: 21.6508 - val_mae: 3.7579\n",
            "Epoch 232/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 18.9009 - mae: 3.2917 - val_loss: 21.1858 - val_mae: 3.6679\n",
            "Epoch 233/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 20.2254 - mae: 3.2144 - val_loss: 21.0869 - val_mae: 3.7509\n",
            "Epoch 234/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 18.7039 - mae: 3.2584 - val_loss: 20.6018 - val_mae: 3.6783\n",
            "Epoch 235/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 19.6682 - mae: 3.1804 - val_loss: 20.6535 - val_mae: 3.7350\n",
            "Epoch 236/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 17.9561 - mae: 3.1860 - val_loss: 20.1724 - val_mae: 3.6783\n",
            "Epoch 237/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 17.7196 - mae: 3.1066 - val_loss: 20.5406 - val_mae: 3.7483\n",
            "Epoch 238/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 17.4717 - mae: 3.1112 - val_loss: 19.2050 - val_mae: 3.5614\n",
            "Epoch 239/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 16.9179 - mae: 3.0553 - val_loss: 19.0896 - val_mae: 3.5797\n",
            "Epoch 240/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 17.3315 - mae: 3.0121 - val_loss: 19.0820 - val_mae: 3.5966\n",
            "Epoch 241/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 17.1892 - mae: 3.0195 - val_loss: 18.4572 - val_mae: 3.5204\n",
            "Epoch 242/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 17.3199 - mae: 2.9376 - val_loss: 18.7827 - val_mae: 3.5734\n",
            "Epoch 243/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 16.3158 - mae: 2.9664 - val_loss: 17.9498 - val_mae: 3.4727\n",
            "Epoch 244/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 14.8775 - mae: 2.8961 - val_loss: 17.3744 - val_mae: 3.3888\n",
            "Epoch 245/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 15.3612 - mae: 2.8670 - val_loss: 17.2749 - val_mae: 3.3980\n",
            "Epoch 246/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 15.0706 - mae: 2.8527 - val_loss: 16.5856 - val_mae: 3.2599\n",
            "Epoch 247/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 14.3524 - mae: 2.8152 - val_loss: 16.2920 - val_mae: 3.2147\n",
            "Epoch 248/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 14.4545 - mae: 2.7770 - val_loss: 16.3339 - val_mae: 3.2850\n",
            "Epoch 249/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 13.3388 - mae: 2.7613 - val_loss: 15.7487 - val_mae: 3.1511\n",
            "Epoch 250/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 13.4898 - mae: 2.6935 - val_loss: 15.7035 - val_mae: 3.2119\n",
            "Epoch 251/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 14.3573 - mae: 2.7174 - val_loss: 15.1952 - val_mae: 3.1125\n",
            "Epoch 252/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 13.8096 - mae: 2.6589 - val_loss: 15.3857 - val_mae: 3.1898\n",
            "Epoch 253/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 13.4294 - mae: 2.6607 - val_loss: 15.4350 - val_mae: 3.2029\n",
            "Epoch 254/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 13.0205 - mae: 2.6495 - val_loss: 15.4651 - val_mae: 3.2078\n",
            "Epoch 255/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.6965 - mae: 2.6476 - val_loss: 14.7568 - val_mae: 3.1179\n",
            "Epoch 256/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.6663 - mae: 2.5971 - val_loss: 14.0868 - val_mae: 3.0060\n",
            "Epoch 257/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.1115 - mae: 2.5899 - val_loss: 13.9864 - val_mae: 3.0097\n",
            "Epoch 258/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 11.9979 - mae: 2.5558 - val_loss: 13.6246 - val_mae: 2.9349\n",
            "Epoch 259/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 11.5989 - mae: 2.5838 - val_loss: 13.5285 - val_mae: 2.9447\n",
            "Epoch 260/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 11.9631 - mae: 2.5098 - val_loss: 13.6878 - val_mae: 2.9951\n",
            "Epoch 261/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 11.7798 - mae: 2.5477 - val_loss: 13.0241 - val_mae: 2.8546\n",
            "Epoch 262/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 11.2919 - mae: 2.4998 - val_loss: 12.9048 - val_mae: 2.8603\n",
            "Epoch 263/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 11.5397 - mae: 2.4702 - val_loss: 13.2500 - val_mae: 2.9438\n",
            "Epoch 264/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 11.1576 - mae: 2.4843 - val_loss: 12.4954 - val_mae: 2.8157\n",
            "Epoch 265/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 11.4261 - mae: 2.4323 - val_loss: 12.7213 - val_mae: 2.8760\n",
            "Epoch 266/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 11.0415 - mae: 2.4329 - val_loss: 12.7099 - val_mae: 2.8832\n",
            "Epoch 267/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 10.6287 - mae: 2.4590 - val_loss: 11.8764 - val_mae: 2.7415\n",
            "Epoch 268/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 10.5232 - mae: 2.4067 - val_loss: 11.5532 - val_mae: 2.5902\n",
            "Epoch 269/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 9.9989 - mae: 2.3461 - val_loss: 11.4732 - val_mae: 2.6873\n",
            "Epoch 270/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.8143 - mae: 2.3369 - val_loss: 11.6575 - val_mae: 2.7362\n",
            "Epoch 271/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 10.0583 - mae: 2.3941 - val_loss: 11.0582 - val_mae: 2.6131\n",
            "Epoch 272/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 10.2311 - mae: 2.3333 - val_loss: 10.8602 - val_mae: 2.5623\n",
            "Epoch 273/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 9.7618 - mae: 2.3181 - val_loss: 10.9875 - val_mae: 2.6396\n",
            "Epoch 274/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.2818 - mae: 2.3049 - val_loss: 10.8739 - val_mae: 2.6263\n",
            "Epoch 275/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 9.4828 - mae: 2.2956 - val_loss: 10.9198 - val_mae: 2.6488\n",
            "Epoch 276/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.8989 - mae: 2.2880 - val_loss: 10.7567 - val_mae: 2.6284\n",
            "Epoch 277/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.8644 - mae: 2.3134 - val_loss: 10.4436 - val_mae: 2.5682\n",
            "Epoch 278/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 9.3270 - mae: 2.2529 - val_loss: 11.3758 - val_mae: 2.7526\n",
            "Epoch 279/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.7952 - mae: 2.3009 - val_loss: 10.1919 - val_mae: 2.5353\n",
            "Epoch 280/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.7749 - mae: 2.2440 - val_loss: 9.8420 - val_mae: 2.4702\n",
            "Epoch 281/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.9058 - mae: 2.2279 - val_loss: 9.6610 - val_mae: 2.4397\n",
            "Epoch 282/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.2593 - mae: 2.2012 - val_loss: 9.6145 - val_mae: 2.4472\n",
            "Epoch 283/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.7298 - mae: 2.1913 - val_loss: 9.2965 - val_mae: 2.3770\n",
            "Epoch 284/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.2987 - mae: 2.1525 - val_loss: 9.6722 - val_mae: 2.4791\n",
            "Epoch 285/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.0081 - mae: 2.1959 - val_loss: 9.1195 - val_mae: 2.3645\n",
            "Epoch 286/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.3769 - mae: 2.1268 - val_loss: 9.9774 - val_mae: 2.5589\n",
            "Epoch 287/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.0659 - mae: 2.1575 - val_loss: 9.7781 - val_mae: 2.5278\n",
            "Epoch 288/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.6768 - mae: 2.1608 - val_loss: 8.8031 - val_mae: 2.3328\n",
            "Epoch 289/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.1836 - mae: 2.1555 - val_loss: 9.2692 - val_mae: 2.4407\n",
            "Epoch 290/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.6157 - mae: 2.1437 - val_loss: 8.4821 - val_mae: 2.2647\n",
            "Epoch 291/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.6659 - mae: 2.1098 - val_loss: 8.4777 - val_mae: 2.2829\n",
            "Epoch 292/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.5998 - mae: 2.0789 - val_loss: 8.9160 - val_mae: 2.3942\n",
            "Epoch 293/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.0368 - mae: 2.0926 - val_loss: 8.6303 - val_mae: 2.3390\n",
            "Epoch 294/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.2343 - mae: 2.1228 - val_loss: 8.2294 - val_mae: 2.2548\n",
            "Epoch 295/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.4022 - mae: 2.0414 - val_loss: 8.7184 - val_mae: 2.3796\n",
            "Epoch 296/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.3968 - mae: 2.1079 - val_loss: 8.5251 - val_mae: 2.3460\n",
            "Epoch 297/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.9320 - mae: 2.0795 - val_loss: 7.8697 - val_mae: 2.1920\n",
            "Epoch 298/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.7824 - mae: 2.0218 - val_loss: 7.6552 - val_mae: 2.1307\n",
            "Epoch 299/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.1203 - mae: 2.0208 - val_loss: 7.5729 - val_mae: 2.1183\n",
            "Epoch 300/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.7537 - mae: 1.9841 - val_loss: 7.6612 - val_mae: 2.1693\n",
            "Epoch 301/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.2600 - mae: 1.9715 - val_loss: 8.4664 - val_mae: 2.3631\n",
            "Epoch 302/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.7130 - mae: 2.0440 - val_loss: 8.0634 - val_mae: 2.2879\n",
            "Epoch 303/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.8117 - mae: 2.0174 - val_loss: 7.7983 - val_mae: 2.2335\n",
            "Epoch 304/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.2708 - mae: 1.9937 - val_loss: 7.1525 - val_mae: 2.0503\n",
            "Epoch 305/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.3256 - mae: 1.9528 - val_loss: 7.3762 - val_mae: 2.1402\n",
            "Epoch 306/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.1272 - mae: 1.9681 - val_loss: 7.1065 - val_mae: 2.0761\n",
            "Epoch 307/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.2598 - mae: 1.9537 - val_loss: 7.0654 - val_mae: 2.0738\n",
            "Epoch 308/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.0255 - mae: 1.9210 - val_loss: 7.1421 - val_mae: 2.1079\n",
            "Epoch 309/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.2372 - mae: 1.9663 - val_loss: 6.7496 - val_mae: 1.9640\n",
            "Epoch 310/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.7438 - mae: 1.8947 - val_loss: 6.6918 - val_mae: 1.9827\n",
            "Epoch 311/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.9798 - mae: 1.9005 - val_loss: 6.6002 - val_mae: 1.9641\n",
            "Epoch 312/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.8694 - mae: 1.8919 - val_loss: 6.6712 - val_mae: 2.0133\n",
            "Epoch 313/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.6869 - mae: 1.8936 - val_loss: 6.4625 - val_mae: 1.9473\n",
            "Epoch 314/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.7611 - mae: 1.9005 - val_loss: 6.3929 - val_mae: 1.9395\n",
            "Epoch 315/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.6786 - mae: 1.8590 - val_loss: 6.6840 - val_mae: 2.0532\n",
            "Epoch 316/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.4022 - mae: 1.8747 - val_loss: 6.2468 - val_mae: 1.9000\n",
            "Epoch 317/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.5321 - mae: 1.8760 - val_loss: 6.1847 - val_mae: 1.8600\n",
            "Epoch 318/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.6864 - mae: 1.8445 - val_loss: 6.1199 - val_mae: 1.8865\n",
            "Epoch 319/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.3062 - mae: 1.7962 - val_loss: 6.1357 - val_mae: 1.9144\n",
            "Epoch 320/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.2385 - mae: 1.8152 - val_loss: 6.1267 - val_mae: 1.9263\n",
            "Epoch 321/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.0038 - mae: 1.7823 - val_loss: 6.4711 - val_mae: 2.0404\n",
            "Epoch 322/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.3866 - mae: 1.8032 - val_loss: 6.6558 - val_mae: 2.0839\n",
            "Epoch 323/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.9755 - mae: 1.8296 - val_loss: 5.9177 - val_mae: 1.8856\n",
            "Epoch 324/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.8107 - mae: 1.7758 - val_loss: 5.7857 - val_mae: 1.8389\n",
            "Epoch 325/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.2558 - mae: 1.8206 - val_loss: 5.6863 - val_mae: 1.8052\n",
            "Epoch 326/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.0395 - mae: 1.7722 - val_loss: 5.7787 - val_mae: 1.8683\n",
            "Epoch 327/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.9326 - mae: 1.7476 - val_loss: 6.3598 - val_mae: 2.0279\n",
            "Epoch 328/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.9039 - mae: 1.8032 - val_loss: 5.6748 - val_mae: 1.8554\n",
            "Epoch 329/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.9152 - mae: 1.7522 - val_loss: 5.7956 - val_mae: 1.9057\n",
            "Epoch 330/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.1756 - mae: 1.8040 - val_loss: 5.9533 - val_mae: 1.9481\n",
            "Epoch 331/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.5977 - mae: 1.7692 - val_loss: 5.3993 - val_mae: 1.7838\n",
            "Epoch 332/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.6991 - mae: 1.7314 - val_loss: 5.3162 - val_mae: 1.7644\n",
            "Epoch 333/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.7245 - mae: 1.7116 - val_loss: 5.4064 - val_mae: 1.8160\n",
            "Epoch 334/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.5920 - mae: 1.7226 - val_loss: 5.4023 - val_mae: 1.8245\n",
            "Epoch 335/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.5319 - mae: 1.6678 - val_loss: 5.9545 - val_mae: 1.9581\n",
            "Epoch 336/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.8818 - mae: 1.7685 - val_loss: 5.4541 - val_mae: 1.8514\n",
            "Epoch 337/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.4921 - mae: 1.7093 - val_loss: 5.8600 - val_mae: 1.9383\n",
            "Epoch 338/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.2654 - mae: 1.7348 - val_loss: 5.1153 - val_mae: 1.7644\n",
            "Epoch 339/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.3917 - mae: 1.6707 - val_loss: 5.1529 - val_mae: 1.7907\n",
            "Epoch 340/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.5875 - mae: 1.6871 - val_loss: 5.2968 - val_mae: 1.8334\n",
            "Epoch 341/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.3155 - mae: 1.6716 - val_loss: 5.6205 - val_mae: 1.8970\n",
            "Epoch 342/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.4064 - mae: 1.6743 - val_loss: 5.9535 - val_mae: 1.9499\n",
            "Epoch 343/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.3593 - mae: 1.6591 - val_loss: 6.2994 - val_mae: 2.0118\n",
            "Epoch 344/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.2718 - mae: 1.6857 - val_loss: 4.9074 - val_mae: 1.7614\n",
            "Epoch 345/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.1202 - mae: 1.6375 - val_loss: 5.0214 - val_mae: 1.7934\n",
            "Epoch 346/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.5838 - mae: 1.6516 - val_loss: 5.1224 - val_mae: 1.8170\n",
            "Epoch 347/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.2754 - mae: 1.6555 - val_loss: 4.7983 - val_mae: 1.7521\n",
            "Epoch 348/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.9972 - mae: 1.6207 - val_loss: 4.8113 - val_mae: 1.7599\n",
            "Epoch 349/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.0054 - mae: 1.5988 - val_loss: 5.3853 - val_mae: 1.8644\n",
            "Epoch 350/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.0454 - mae: 1.6331 - val_loss: 4.6026 - val_mae: 1.7126\n",
            "Epoch 351/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.9575 - mae: 1.6438 - val_loss: 4.4733 - val_mae: 1.6557\n",
            "Epoch 352/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.7614 - mae: 1.5979 - val_loss: 4.4447 - val_mae: 1.6580\n",
            "Epoch 353/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.9378 - mae: 1.5723 - val_loss: 4.5898 - val_mae: 1.7219\n",
            "Epoch 354/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.7592 - mae: 1.5645 - val_loss: 4.6104 - val_mae: 1.7308\n",
            "Epoch 355/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.6935 - mae: 1.5279 - val_loss: 5.0366 - val_mae: 1.8108\n",
            "Epoch 356/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.8545 - mae: 1.5602 - val_loss: 4.4984 - val_mae: 1.7082\n",
            "Epoch 357/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.8314 - mae: 1.5782 - val_loss: 4.2420 - val_mae: 1.6244\n",
            "Epoch 358/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.8897 - mae: 1.5346 - val_loss: 4.7043 - val_mae: 1.7514\n",
            "Epoch 359/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.6437 - mae: 1.5504 - val_loss: 4.8038 - val_mae: 1.7697\n",
            "Epoch 360/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.6896 - mae: 1.5599 - val_loss: 4.5652 - val_mae: 1.7260\n",
            "Epoch 361/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4719 - mae: 1.5359 - val_loss: 4.2546 - val_mae: 1.6704\n",
            "Epoch 362/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.5586 - mae: 1.5204 - val_loss: 4.0842 - val_mae: 1.5950\n",
            "Epoch 363/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.3497 - mae: 1.5039 - val_loss: 4.2694 - val_mae: 1.6788\n",
            "Epoch 364/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4238 - mae: 1.5095 - val_loss: 4.5478 - val_mae: 1.7273\n",
            "Epoch 365/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3485 - mae: 1.5108 - val_loss: 4.0539 - val_mae: 1.6190\n",
            "Epoch 366/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3615 - mae: 1.4936 - val_loss: 4.4705 - val_mae: 1.7167\n",
            "Epoch 367/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.2664 - mae: 1.5136 - val_loss: 3.9908 - val_mae: 1.6085\n",
            "Epoch 368/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3129 - mae: 1.4586 - val_loss: 4.5471 - val_mae: 1.7266\n",
            "Epoch 369/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.5790 - mae: 1.5007 - val_loss: 4.1568 - val_mae: 1.6608\n",
            "Epoch 370/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3010 - mae: 1.4846 - val_loss: 3.9259 - val_mae: 1.6021\n",
            "Epoch 371/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.2452 - mae: 1.4692 - val_loss: 3.8193 - val_mae: 1.5428\n",
            "Epoch 372/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.2648 - mae: 1.4832 - val_loss: 3.8388 - val_mae: 1.5742\n",
            "Epoch 373/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.2055 - mae: 1.4481 - val_loss: 3.9362 - val_mae: 1.6085\n",
            "Epoch 374/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.2282 - mae: 1.4450 - val_loss: 4.4384 - val_mae: 1.7056\n",
            "Epoch 375/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1625 - mae: 1.4664 - val_loss: 3.8921 - val_mae: 1.6009\n",
            "Epoch 376/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.0688 - mae: 1.4458 - val_loss: 4.0771 - val_mae: 1.6473\n",
            "Epoch 377/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.9411 - mae: 1.4351 - val_loss: 3.7040 - val_mae: 1.4996\n",
            "Epoch 378/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1631 - mae: 1.4383 - val_loss: 4.3394 - val_mae: 1.6893\n",
            "Epoch 379/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.0016 - mae: 1.4430 - val_loss: 3.7988 - val_mae: 1.5893\n",
            "Epoch 380/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.1340 - mae: 1.4385 - val_loss: 3.7048 - val_mae: 1.5630\n",
            "Epoch 381/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.2395 - mae: 1.4178 - val_loss: 3.5715 - val_mae: 1.4863\n",
            "Epoch 382/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.1947 - mae: 1.4398 - val_loss: 3.5424 - val_mae: 1.4939\n",
            "Epoch 383/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.8578 - mae: 1.3972 - val_loss: 3.5127 - val_mae: 1.4853\n",
            "Epoch 384/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0590 - mae: 1.4062 - val_loss: 3.7729 - val_mae: 1.5842\n",
            "Epoch 385/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.8376 - mae: 1.3939 - val_loss: 3.5104 - val_mae: 1.5052\n",
            "Epoch 386/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9251 - mae: 1.3936 - val_loss: 3.4663 - val_mae: 1.4885\n",
            "Epoch 387/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0187 - mae: 1.3791 - val_loss: 3.9783 - val_mae: 1.6258\n",
            "Epoch 388/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0729 - mae: 1.3916 - val_loss: 4.6815 - val_mae: 1.7431\n",
            "Epoch 389/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9219 - mae: 1.3972 - val_loss: 3.9930 - val_mae: 1.6295\n",
            "Epoch 390/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7932 - mae: 1.3628 - val_loss: 3.8213 - val_mae: 1.5967\n",
            "Epoch 391/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8658 - mae: 1.3852 - val_loss: 3.3973 - val_mae: 1.4876\n",
            "Epoch 392/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.1041 - mae: 1.3697 - val_loss: 3.6383 - val_mae: 1.5501\n",
            "Epoch 393/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7084 - mae: 1.3627 - val_loss: 3.4508 - val_mae: 1.5073\n",
            "Epoch 394/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.7755 - mae: 1.3426 - val_loss: 3.5758 - val_mae: 1.5387\n",
            "Epoch 395/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6542 - mae: 1.3329 - val_loss: 4.2116 - val_mae: 1.6629\n",
            "Epoch 396/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.6455 - mae: 1.3264 - val_loss: 3.2717 - val_mae: 1.4547\n",
            "Epoch 397/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8918 - mae: 1.3275 - val_loss: 3.4484 - val_mae: 1.5067\n",
            "Epoch 398/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6291 - mae: 1.3504 - val_loss: 3.3607 - val_mae: 1.4886\n",
            "Epoch 399/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5710 - mae: 1.3369 - val_loss: 3.2292 - val_mae: 1.4457\n",
            "Epoch 400/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6043 - mae: 1.3155 - val_loss: 3.1892 - val_mae: 1.4286\n",
            "Epoch 401/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5623 - mae: 1.3255 - val_loss: 3.6383 - val_mae: 1.5484\n",
            "Epoch 402/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7124 - mae: 1.3455 - val_loss: 3.2222 - val_mae: 1.4449\n",
            "Epoch 403/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4846 - mae: 1.3145 - val_loss: 3.2728 - val_mae: 1.4602\n",
            "Epoch 404/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8323 - mae: 1.3369 - val_loss: 3.2053 - val_mae: 1.4390\n",
            "Epoch 405/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5811 - mae: 1.3250 - val_loss: 3.6338 - val_mae: 1.5451\n",
            "Epoch 406/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4934 - mae: 1.3060 - val_loss: 3.3027 - val_mae: 1.4670\n",
            "Epoch 407/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4146 - mae: 1.3127 - val_loss: 3.0496 - val_mae: 1.3768\n",
            "Epoch 408/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.5481 - mae: 1.3024 - val_loss: 3.0539 - val_mae: 1.3952\n",
            "Epoch 409/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4623 - mae: 1.3141 - val_loss: 3.0399 - val_mae: 1.3905\n",
            "Epoch 410/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.3931 - mae: 1.2927 - val_loss: 3.1315 - val_mae: 1.4184\n",
            "Epoch 411/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4329 - mae: 1.2732 - val_loss: 3.4365 - val_mae: 1.4959\n",
            "Epoch 412/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5287 - mae: 1.3220 - val_loss: 3.3027 - val_mae: 1.4629\n",
            "Epoch 413/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4239 - mae: 1.3042 - val_loss: 2.9862 - val_mae: 1.3778\n",
            "Epoch 414/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.3714 - mae: 1.2549 - val_loss: 4.0968 - val_mae: 1.6130\n",
            "Epoch 415/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.2708 - mae: 1.2611 - val_loss: 3.3338 - val_mae: 1.4720\n",
            "Epoch 416/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4450 - mae: 1.2827 - val_loss: 3.1450 - val_mae: 1.4212\n",
            "Epoch 417/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.3663 - mae: 1.2579 - val_loss: 3.4383 - val_mae: 1.4966\n",
            "Epoch 418/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.3856 - mae: 1.2468 - val_loss: 3.1668 - val_mae: 1.4310\n",
            "Epoch 419/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4060 - mae: 1.2619 - val_loss: 3.0169 - val_mae: 1.3871\n",
            "Epoch 420/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.2966 - mae: 1.2502 - val_loss: 2.9077 - val_mae: 1.3626\n",
            "Epoch 421/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4859 - mae: 1.2733 - val_loss: 3.0505 - val_mae: 1.3980\n",
            "Epoch 422/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.2742 - mae: 1.2296 - val_loss: 3.0738 - val_mae: 1.4034\n",
            "Epoch 423/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.3839 - mae: 1.2494 - val_loss: 3.1771 - val_mae: 1.4344\n",
            "Epoch 424/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.1403 - mae: 1.2244 - val_loss: 2.8360 - val_mae: 1.3229\n",
            "Epoch 425/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.3279 - mae: 1.1983 - val_loss: 3.4174 - val_mae: 1.4896\n",
            "Epoch 426/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.1913 - mae: 1.2341 - val_loss: 3.0234 - val_mae: 1.3918\n",
            "Epoch 427/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.1983 - mae: 1.2130 - val_loss: 3.0054 - val_mae: 1.3867\n",
            "Epoch 428/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.3155 - mae: 1.2374 - val_loss: 2.8228 - val_mae: 1.3475\n",
            "Epoch 429/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.3085 - mae: 1.1903 - val_loss: 4.0374 - val_mae: 1.5853\n",
            "Epoch 430/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.3047 - mae: 1.2376 - val_loss: 2.7702 - val_mae: 1.3282\n",
            "Epoch 431/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.2784 - mae: 1.1988 - val_loss: 3.4094 - val_mae: 1.4826\n",
            "Epoch 432/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.2776 - mae: 1.2338 - val_loss: 3.8308 - val_mae: 1.5510\n",
            "Epoch 433/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.1517 - mae: 1.2002 - val_loss: 2.7349 - val_mae: 1.3093\n",
            "Epoch 434/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.3495 - mae: 1.2024 - val_loss: 3.3901 - val_mae: 1.4724\n",
            "Epoch 435/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.0847 - mae: 1.1978 - val_loss: 2.8367 - val_mae: 1.3499\n",
            "Epoch 436/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.1242 - mae: 1.1792 - val_loss: 2.7873 - val_mae: 1.3406\n",
            "Epoch 437/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.1568 - mae: 1.1564 - val_loss: 3.3548 - val_mae: 1.4661\n",
            "Epoch 438/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.0551 - mae: 1.2097 - val_loss: 2.7579 - val_mae: 1.3302\n",
            "Epoch 439/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.9899 - mae: 1.1860 - val_loss: 2.6809 - val_mae: 1.3030\n",
            "Epoch 440/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.2118 - mae: 1.2080 - val_loss: 3.7831 - val_mae: 1.5333\n",
            "Epoch 441/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.2295 - mae: 1.1938 - val_loss: 2.7712 - val_mae: 1.3346\n",
            "Epoch 442/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.1379 - mae: 1.1842 - val_loss: 2.6499 - val_mae: 1.2848\n",
            "Epoch 443/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.0692 - mae: 1.1863 - val_loss: 2.7629 - val_mae: 1.3279\n",
            "Epoch 444/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.2100 - mae: 1.1629 - val_loss: 2.9713 - val_mae: 1.3839\n",
            "Epoch 445/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.1455 - mae: 1.1729 - val_loss: 2.5981 - val_mae: 1.2746\n",
            "Epoch 446/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.2478 - mae: 1.1872 - val_loss: 2.5843 - val_mae: 1.2701\n",
            "Epoch 447/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0732 - mae: 1.1473 - val_loss: 3.2794 - val_mae: 1.4361\n",
            "Epoch 448/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.0592 - mae: 1.1691 - val_loss: 2.6899 - val_mae: 1.3074\n",
            "Epoch 449/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.9472 - mae: 1.1661 - val_loss: 2.5626 - val_mae: 1.2547\n",
            "Epoch 450/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.1276 - mae: 1.1922 - val_loss: 2.5975 - val_mae: 1.2847\n",
            "Epoch 451/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.9574 - mae: 1.1609 - val_loss: 2.5752 - val_mae: 1.2748\n",
            "Epoch 452/1000\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.9396 - mae: 1.1486 - val_loss: 2.6747 - val_mae: 1.3040\n",
            "Epoch 453/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.0142 - mae: 1.1850 - val_loss: 2.5485 - val_mae: 1.2570\n",
            "Epoch 454/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.0215 - mae: 1.1636 - val_loss: 2.8123 - val_mae: 1.3399\n",
            "Epoch 455/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.9976 - mae: 1.1554 - val_loss: 2.8573 - val_mae: 1.3471\n",
            "Epoch 456/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.9383 - mae: 1.1505 - val_loss: 3.2951 - val_mae: 1.4352\n",
            "Epoch 457/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.9359 - mae: 1.1533 - val_loss: 2.6945 - val_mae: 1.3066\n",
            "Epoch 458/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.0087 - mae: 1.1620 - val_loss: 2.5070 - val_mae: 1.2412\n",
            "Epoch 459/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.0404 - mae: 1.1341 - val_loss: 3.6774 - val_mae: 1.4902\n",
            "Epoch 460/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.8943 - mae: 1.1458 - val_loss: 2.9825 - val_mae: 1.3711\n",
            "Epoch 461/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.9445 - mae: 1.1272 - val_loss: 2.5537 - val_mae: 1.2635\n",
            "Epoch 462/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.0464 - mae: 1.1664 - val_loss: 2.7709 - val_mae: 1.3165\n",
            "Epoch 463/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.8945 - mae: 1.1472 - val_loss: 2.8126 - val_mae: 1.3271\n",
            "Epoch 464/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.8792 - mae: 1.1214 - val_loss: 3.1991 - val_mae: 1.4117\n",
            "Epoch 465/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.0740 - mae: 1.1513 - val_loss: 2.4565 - val_mae: 1.2208\n",
            "Epoch 466/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.9734 - mae: 1.1297 - val_loss: 3.4614 - val_mae: 1.4490\n",
            "Epoch 467/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8766 - mae: 1.1414 - val_loss: 3.2070 - val_mae: 1.4038\n",
            "Epoch 468/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.9602 - mae: 1.1212 - val_loss: 2.6240 - val_mae: 1.2858\n",
            "Epoch 469/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.9419 - mae: 1.1300 - val_loss: 3.3087 - val_mae: 1.4195\n",
            "Epoch 470/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.9209 - mae: 1.1529 - val_loss: 3.3432 - val_mae: 1.4267\n",
            "Epoch 471/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.9262 - mae: 1.1386 - val_loss: 3.1719 - val_mae: 1.3940\n",
            "Epoch 472/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.9434 - mae: 1.1526 - val_loss: 2.6261 - val_mae: 1.2829\n",
            "Epoch 473/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.8754 - mae: 1.1168 - val_loss: 2.4552 - val_mae: 1.1938\n",
            "Epoch 474/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.9336 - mae: 1.1064 - val_loss: 2.4385 - val_mae: 1.1937\n",
            "Epoch 475/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.7385 - mae: 1.0978 - val_loss: 2.6865 - val_mae: 1.2961\n",
            "Epoch 476/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.9490 - mae: 1.1233 - val_loss: 2.4083 - val_mae: 1.2015\n",
            "Epoch 477/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.7862 - mae: 1.1020 - val_loss: 2.6185 - val_mae: 1.2778\n",
            "Epoch 478/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.9802 - mae: 1.1528 - val_loss: 2.6076 - val_mae: 1.2739\n",
            "Epoch 479/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.8454 - mae: 1.1195 - val_loss: 2.8369 - val_mae: 1.3231\n",
            "Epoch 480/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8690 - mae: 1.1148 - val_loss: 2.7758 - val_mae: 1.3127\n",
            "Epoch 481/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.7917 - mae: 1.0864 - val_loss: 2.5971 - val_mae: 1.2700\n",
            "Epoch 482/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.7544 - mae: 1.0846 - val_loss: 2.6958 - val_mae: 1.2947\n",
            "Epoch 483/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.8962 - mae: 1.0976 - val_loss: 2.8185 - val_mae: 1.3197\n",
            "Epoch 484/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.7772 - mae: 1.0925 - val_loss: 2.7065 - val_mae: 1.2945\n",
            "Epoch 485/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7929 - mae: 1.0829 - val_loss: 2.3943 - val_mae: 1.2056\n",
            "Epoch 486/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.8034 - mae: 1.0914 - val_loss: 2.7503 - val_mae: 1.2964\n",
            "Epoch 487/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.9037 - mae: 1.0987 - val_loss: 3.0966 - val_mae: 1.3656\n",
            "Epoch 488/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.8051 - mae: 1.1182 - val_loss: 2.6022 - val_mae: 1.2656\n",
            "Epoch 489/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.7717 - mae: 1.0812 - val_loss: 2.3290 - val_mae: 1.1807\n",
            "Epoch 490/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.8004 - mae: 1.0659 - val_loss: 3.2812 - val_mae: 1.3995\n",
            "Epoch 491/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.9481 - mae: 1.1002 - val_loss: 3.4147 - val_mae: 1.4259\n",
            "Epoch 492/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.9069 - mae: 1.0721 - val_loss: 3.2674 - val_mae: 1.3947\n",
            "Epoch 493/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8439 - mae: 1.0925 - val_loss: 2.5542 - val_mae: 1.2567\n",
            "Epoch 494/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.7728 - mae: 1.0767 - val_loss: 2.4013 - val_mae: 1.2138\n",
            "Epoch 495/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6940 - mae: 1.0571 - val_loss: 2.4971 - val_mae: 1.2433\n",
            "Epoch 496/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.7261 - mae: 1.0525 - val_loss: 2.6828 - val_mae: 1.2836\n",
            "Epoch 497/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.9255 - mae: 1.1005 - val_loss: 2.7796 - val_mae: 1.2984\n",
            "Epoch 498/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.7422 - mae: 1.0505 - val_loss: 2.2996 - val_mae: 1.1702\n",
            "Epoch 499/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.8333 - mae: 1.0899 - val_loss: 2.7484 - val_mae: 1.2938\n",
            "Epoch 500/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.7350 - mae: 1.0698 - val_loss: 2.3246 - val_mae: 1.1855\n",
            "Epoch 501/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7439 - mae: 1.0418 - val_loss: 2.6554 - val_mae: 1.2745\n",
            "Epoch 502/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.7514 - mae: 1.0614 - val_loss: 2.8368 - val_mae: 1.3067\n",
            "Epoch 503/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.7255 - mae: 1.0306 - val_loss: 3.2137 - val_mae: 1.3837\n",
            "Epoch 504/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.7282 - mae: 1.0526 - val_loss: 2.4771 - val_mae: 1.2344\n",
            "Epoch 505/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.7404 - mae: 1.0805 - val_loss: 2.6668 - val_mae: 1.2744\n",
            "Epoch 506/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.6773 - mae: 1.0354 - val_loss: 3.0355 - val_mae: 1.3453\n",
            "Epoch 507/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6859 - mae: 1.0624 - val_loss: 2.3606 - val_mae: 1.2025\n",
            "Epoch 508/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.7819 - mae: 1.0463 - val_loss: 2.3054 - val_mae: 1.1817\n",
            "Epoch 509/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8712 - mae: 1.0537 - val_loss: 2.3413 - val_mae: 1.1957\n",
            "Epoch 510/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6496 - mae: 1.0358 - val_loss: 2.3994 - val_mae: 1.2134\n",
            "Epoch 511/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.7597 - mae: 1.0561 - val_loss: 3.3882 - val_mae: 1.4255\n",
            "Epoch 512/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.7316 - mae: 1.0925 - val_loss: 2.2297 - val_mae: 1.1467\n",
            "Epoch 513/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.7407 - mae: 1.0507 - val_loss: 2.3909 - val_mae: 1.2098\n",
            "Epoch 514/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6160 - mae: 1.0267 - val_loss: 2.5222 - val_mae: 1.2439\n",
            "Epoch 515/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6605 - mae: 1.0250 - val_loss: 2.3624 - val_mae: 1.2013\n",
            "Epoch 516/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5612 - mae: 1.0339 - val_loss: 2.2340 - val_mae: 1.1267\n",
            "Epoch 517/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6455 - mae: 1.0418 - val_loss: 2.3263 - val_mae: 1.1437\n",
            "Epoch 518/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.7560 - mae: 1.0568 - val_loss: 2.3578 - val_mae: 1.2004\n",
            "Epoch 519/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5744 - mae: 1.0067 - val_loss: 3.0335 - val_mae: 1.3393\n",
            "Epoch 520/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5710 - mae: 1.0315 - val_loss: 2.7789 - val_mae: 1.2883\n",
            "Epoch 521/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.7350 - mae: 1.0589 - val_loss: 2.2443 - val_mae: 1.1277\n",
            "Epoch 522/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6244 - mae: 1.0073 - val_loss: 2.2255 - val_mae: 1.1527\n",
            "Epoch 523/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6090 - mae: 1.0278 - val_loss: 2.3515 - val_mae: 1.1960\n",
            "Epoch 524/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6405 - mae: 1.0332 - val_loss: 2.1988 - val_mae: 1.1433\n",
            "Epoch 525/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6254 - mae: 1.0271 - val_loss: 3.0136 - val_mae: 1.3329\n",
            "Epoch 526/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5494 - mae: 0.9843 - val_loss: 3.3030 - val_mae: 1.4059\n",
            "Epoch 527/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.6244 - mae: 1.0190 - val_loss: 3.0834 - val_mae: 1.3533\n",
            "Epoch 528/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6871 - mae: 1.0161 - val_loss: 2.1569 - val_mae: 1.1299\n",
            "Epoch 529/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5614 - mae: 0.9948 - val_loss: 2.2767 - val_mae: 1.1746\n",
            "Epoch 530/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6150 - mae: 1.0114 - val_loss: 2.9694 - val_mae: 1.3257\n",
            "Epoch 531/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6418 - mae: 1.0198 - val_loss: 2.2397 - val_mae: 1.1623\n",
            "Epoch 532/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5324 - mae: 1.0252 - val_loss: 2.2521 - val_mae: 1.1662\n",
            "Epoch 533/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4949 - mae: 0.9893 - val_loss: 2.1326 - val_mae: 1.1223\n",
            "Epoch 534/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4443 - mae: 0.9817 - val_loss: 2.2732 - val_mae: 1.1723\n",
            "Epoch 535/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6681 - mae: 1.0416 - val_loss: 2.3431 - val_mae: 1.1921\n",
            "Epoch 536/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5277 - mae: 1.0126 - val_loss: 2.3190 - val_mae: 1.1852\n",
            "Epoch 537/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5255 - mae: 0.9975 - val_loss: 2.1491 - val_mae: 1.1052\n",
            "Epoch 538/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5580 - mae: 1.0056 - val_loss: 2.1640 - val_mae: 1.1353\n",
            "Epoch 539/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5297 - mae: 0.9848 - val_loss: 2.1796 - val_mae: 1.1406\n",
            "Epoch 540/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4656 - mae: 0.9708 - val_loss: 2.1969 - val_mae: 1.1465\n",
            "Epoch 541/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5511 - mae: 1.0061 - val_loss: 2.1345 - val_mae: 1.1247\n",
            "Epoch 542/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6496 - mae: 0.9882 - val_loss: 2.4129 - val_mae: 1.2022\n",
            "Epoch 543/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6014 - mae: 1.0067 - val_loss: 2.0942 - val_mae: 1.1034\n",
            "Epoch 544/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5279 - mae: 1.0068 - val_loss: 2.1211 - val_mae: 1.1220\n",
            "Epoch 545/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4184 - mae: 0.9607 - val_loss: 2.1462 - val_mae: 1.1040\n",
            "Epoch 546/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.6477 - mae: 0.9995 - val_loss: 2.0997 - val_mae: 1.1151\n",
            "Epoch 547/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4566 - mae: 0.9728 - val_loss: 2.0684 - val_mae: 1.0945\n",
            "Epoch 548/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5679 - mae: 0.9952 - val_loss: 2.0576 - val_mae: 1.0956\n",
            "Epoch 549/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4735 - mae: 0.9748 - val_loss: 2.0833 - val_mae: 1.1094\n",
            "Epoch 550/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5405 - mae: 0.9550 - val_loss: 2.2594 - val_mae: 1.1634\n",
            "Epoch 551/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4401 - mae: 0.9591 - val_loss: 2.3770 - val_mae: 1.1894\n",
            "Epoch 552/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4093 - mae: 0.9744 - val_loss: 2.1013 - val_mae: 1.1178\n",
            "Epoch 553/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6201 - mae: 1.0203 - val_loss: 2.6433 - val_mae: 1.2512\n",
            "Epoch 554/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4086 - mae: 0.9685 - val_loss: 2.0576 - val_mae: 1.1013\n",
            "Epoch 555/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4098 - mae: 0.9500 - val_loss: 2.0476 - val_mae: 1.0871\n",
            "Epoch 556/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4082 - mae: 0.9221 - val_loss: 2.9459 - val_mae: 1.3275\n",
            "Epoch 557/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5308 - mae: 0.9543 - val_loss: 2.7844 - val_mae: 1.2897\n",
            "Epoch 558/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3685 - mae: 0.9349 - val_loss: 2.0874 - val_mae: 1.0949\n",
            "Epoch 559/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4564 - mae: 0.9600 - val_loss: 2.0510 - val_mae: 1.1020\n",
            "Epoch 560/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3714 - mae: 0.9519 - val_loss: 2.0328 - val_mae: 1.0842\n",
            "Epoch 561/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4357 - mae: 0.9409 - val_loss: 2.0341 - val_mae: 1.0833\n",
            "Epoch 562/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4746 - mae: 0.9458 - val_loss: 2.6407 - val_mae: 1.2561\n",
            "Epoch 563/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4225 - mae: 0.9657 - val_loss: 2.0514 - val_mae: 1.1043\n",
            "Epoch 564/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5957 - mae: 0.9385 - val_loss: 2.8521 - val_mae: 1.3078\n",
            "Epoch 565/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4974 - mae: 0.9543 - val_loss: 2.0654 - val_mae: 1.1078\n",
            "Epoch 566/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3870 - mae: 0.9405 - val_loss: 1.9936 - val_mae: 1.0783\n",
            "Epoch 567/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4709 - mae: 0.9546 - val_loss: 1.9794 - val_mae: 1.0716\n",
            "Epoch 568/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4117 - mae: 0.9041 - val_loss: 2.0537 - val_mae: 1.1032\n",
            "Epoch 569/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3280 - mae: 0.9101 - val_loss: 2.1439 - val_mae: 1.1258\n",
            "Epoch 570/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3995 - mae: 0.9427 - val_loss: 2.0165 - val_mae: 1.0818\n",
            "Epoch 571/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4637 - mae: 0.9459 - val_loss: 1.9723 - val_mae: 1.0745\n",
            "Epoch 572/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3274 - mae: 0.9282 - val_loss: 2.0453 - val_mae: 1.1020\n",
            "Epoch 573/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4484 - mae: 0.9471 - val_loss: 1.9804 - val_mae: 1.0786\n",
            "Epoch 574/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4954 - mae: 0.9503 - val_loss: 2.2881 - val_mae: 1.1557\n",
            "Epoch 575/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3738 - mae: 0.9469 - val_loss: 1.9594 - val_mae: 1.0715\n",
            "Epoch 576/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4002 - mae: 0.9283 - val_loss: 2.2794 - val_mae: 1.1529\n",
            "Epoch 577/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4890 - mae: 0.9602 - val_loss: 1.9493 - val_mae: 1.0631\n",
            "Epoch 578/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3225 - mae: 0.9105 - val_loss: 2.0364 - val_mae: 1.0970\n",
            "Epoch 579/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3616 - mae: 0.9498 - val_loss: 1.9938 - val_mae: 1.0712\n",
            "Epoch 580/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4497 - mae: 0.9449 - val_loss: 2.1623 - val_mae: 1.1263\n",
            "Epoch 581/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4073 - mae: 0.9600 - val_loss: 1.9342 - val_mae: 1.0602\n",
            "Epoch 582/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3351 - mae: 0.9188 - val_loss: 2.0071 - val_mae: 1.0880\n",
            "Epoch 583/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3106 - mae: 0.9080 - val_loss: 2.2647 - val_mae: 1.1496\n",
            "Epoch 584/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3576 - mae: 0.9480 - val_loss: 1.9871 - val_mae: 1.0830\n",
            "Epoch 585/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3297 - mae: 0.9325 - val_loss: 1.9659 - val_mae: 1.0771\n",
            "Epoch 586/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2544 - mae: 0.8994 - val_loss: 1.9870 - val_mae: 1.0839\n",
            "Epoch 587/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3731 - mae: 0.9146 - val_loss: 2.0786 - val_mae: 1.1055\n",
            "Epoch 588/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3840 - mae: 0.9138 - val_loss: 2.0930 - val_mae: 1.1069\n",
            "Epoch 589/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3868 - mae: 0.9193 - val_loss: 1.9083 - val_mae: 1.0510\n",
            "Epoch 590/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4016 - mae: 0.9143 - val_loss: 2.0321 - val_mae: 1.0884\n",
            "Epoch 591/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5922 - mae: 0.9276 - val_loss: 2.7672 - val_mae: 1.2994\n",
            "Epoch 592/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4332 - mae: 0.9235 - val_loss: 2.1400 - val_mae: 1.1158\n",
            "Epoch 593/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3617 - mae: 0.9052 - val_loss: 2.5815 - val_mae: 1.2510\n",
            "Epoch 594/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3132 - mae: 0.9054 - val_loss: 1.9299 - val_mae: 1.0663\n",
            "Epoch 595/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3799 - mae: 0.9228 - val_loss: 1.9237 - val_mae: 1.0662\n",
            "Epoch 596/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2940 - mae: 0.9066 - val_loss: 1.9761 - val_mae: 1.0799\n",
            "Epoch 597/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3314 - mae: 0.9256 - val_loss: 2.0267 - val_mae: 1.0942\n",
            "Epoch 598/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3504 - mae: 0.9230 - val_loss: 1.8990 - val_mae: 1.0599\n",
            "Epoch 599/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3311 - mae: 0.9156 - val_loss: 2.0082 - val_mae: 1.0869\n",
            "Epoch 600/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2905 - mae: 0.8910 - val_loss: 2.0826 - val_mae: 1.1042\n",
            "Epoch 601/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2556 - mae: 0.8940 - val_loss: 1.9483 - val_mae: 1.0728\n",
            "Epoch 602/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3436 - mae: 0.9411 - val_loss: 2.0830 - val_mae: 1.1042\n",
            "Epoch 603/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3302 - mae: 0.8943 - val_loss: 2.8718 - val_mae: 1.3362\n",
            "Epoch 604/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2604 - mae: 0.8851 - val_loss: 1.8722 - val_mae: 1.0525\n",
            "Epoch 605/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3254 - mae: 0.8942 - val_loss: 1.9969 - val_mae: 1.0887\n",
            "Epoch 606/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2034 - mae: 0.8663 - val_loss: 2.0376 - val_mae: 1.0949\n",
            "Epoch 607/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3199 - mae: 0.8897 - val_loss: 3.0499 - val_mae: 1.3823\n",
            "Epoch 608/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3269 - mae: 0.9406 - val_loss: 1.8962 - val_mae: 1.0608\n",
            "Epoch 609/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2442 - mae: 0.8945 - val_loss: 1.9699 - val_mae: 1.0817\n",
            "Epoch 610/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2670 - mae: 0.8827 - val_loss: 2.3609 - val_mae: 1.1973\n",
            "Epoch 611/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2292 - mae: 0.8843 - val_loss: 1.9915 - val_mae: 1.0833\n",
            "Epoch 612/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3114 - mae: 0.9149 - val_loss: 1.9092 - val_mae: 1.0644\n",
            "Epoch 613/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3749 - mae: 0.8889 - val_loss: 1.8451 - val_mae: 1.0448\n",
            "Epoch 614/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2744 - mae: 0.8859 - val_loss: 1.9711 - val_mae: 1.0840\n",
            "Epoch 615/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2301 - mae: 0.8715 - val_loss: 1.8290 - val_mae: 1.0407\n",
            "Epoch 616/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1982 - mae: 0.8826 - val_loss: 1.8451 - val_mae: 1.0439\n",
            "Epoch 617/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2699 - mae: 0.8996 - val_loss: 2.1319 - val_mae: 1.1317\n",
            "Epoch 618/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2558 - mae: 0.8800 - val_loss: 1.9886 - val_mae: 1.0794\n",
            "Epoch 619/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3175 - mae: 0.8962 - val_loss: 3.3025 - val_mae: 1.4441\n",
            "Epoch 620/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3587 - mae: 0.9209 - val_loss: 2.3168 - val_mae: 1.1868\n",
            "Epoch 621/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2260 - mae: 0.8791 - val_loss: 2.1483 - val_mae: 1.1383\n",
            "Epoch 622/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1988 - mae: 0.8795 - val_loss: 2.1062 - val_mae: 1.1284\n",
            "Epoch 623/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3460 - mae: 0.9598 - val_loss: 1.8057 - val_mae: 1.0351\n",
            "Epoch 624/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2832 - mae: 0.8876 - val_loss: 1.9247 - val_mae: 1.0731\n",
            "Epoch 625/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3869 - mae: 0.9238 - val_loss: 1.8174 - val_mae: 1.0344\n",
            "Epoch 626/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2034 - mae: 0.8830 - val_loss: 1.7987 - val_mae: 1.0329\n",
            "Epoch 627/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3324 - mae: 0.8733 - val_loss: 2.2091 - val_mae: 1.1612\n",
            "Epoch 628/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2080 - mae: 0.8657 - val_loss: 1.8651 - val_mae: 1.0546\n",
            "Epoch 629/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4149 - mae: 0.9051 - val_loss: 1.8561 - val_mae: 1.0431\n",
            "Epoch 630/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2358 - mae: 0.8586 - val_loss: 1.8863 - val_mae: 1.0531\n",
            "Epoch 631/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1957 - mae: 0.9026 - val_loss: 1.7903 - val_mae: 1.0330\n",
            "Epoch 632/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2266 - mae: 0.8747 - val_loss: 2.0221 - val_mae: 1.1056\n",
            "Epoch 633/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2485 - mae: 0.8911 - val_loss: 1.8002 - val_mae: 1.0368\n",
            "Epoch 634/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1593 - mae: 0.8448 - val_loss: 1.9001 - val_mae: 1.0628\n",
            "Epoch 635/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1967 - mae: 0.8893 - val_loss: 2.0090 - val_mae: 1.0835\n",
            "Epoch 636/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3270 - mae: 0.8935 - val_loss: 1.9212 - val_mae: 1.0728\n",
            "Epoch 637/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2028 - mae: 0.8817 - val_loss: 1.8307 - val_mae: 1.0472\n",
            "Epoch 638/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2979 - mae: 0.8811 - val_loss: 2.5965 - val_mae: 1.2814\n",
            "Epoch 639/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2978 - mae: 0.9138 - val_loss: 1.8773 - val_mae: 1.0613\n",
            "Epoch 640/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2329 - mae: 0.8860 - val_loss: 1.7896 - val_mae: 1.0335\n",
            "Epoch 641/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2289 - mae: 0.8811 - val_loss: 1.7662 - val_mae: 1.0238\n",
            "Epoch 642/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3303 - mae: 0.8825 - val_loss: 1.7701 - val_mae: 1.0301\n",
            "Epoch 643/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3047 - mae: 0.9000 - val_loss: 1.7640 - val_mae: 1.0252\n",
            "Epoch 644/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3302 - mae: 0.8882 - val_loss: 2.4778 - val_mae: 1.2478\n",
            "Epoch 645/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2019 - mae: 0.8760 - val_loss: 1.7697 - val_mae: 1.0212\n",
            "Epoch 646/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2549 - mae: 0.8741 - val_loss: 1.7982 - val_mae: 1.0381\n",
            "Epoch 647/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2505 - mae: 0.8810 - val_loss: 1.7819 - val_mae: 1.0284\n",
            "Epoch 648/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2338 - mae: 0.8800 - val_loss: 1.8015 - val_mae: 1.0356\n",
            "Epoch 649/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2365 - mae: 0.8843 - val_loss: 1.7729 - val_mae: 1.0279\n",
            "Epoch 650/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2628 - mae: 0.8942 - val_loss: 1.8103 - val_mae: 1.0336\n",
            "Epoch 651/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3427 - mae: 0.8755 - val_loss: 2.1905 - val_mae: 1.1658\n",
            "Epoch 652/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2163 - mae: 0.8861 - val_loss: 1.8511 - val_mae: 1.0535\n",
            "Epoch 653/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1978 - mae: 0.8543 - val_loss: 1.8743 - val_mae: 1.0631\n",
            "Epoch 654/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2034 - mae: 0.8862 - val_loss: 1.7613 - val_mae: 1.0253\n",
            "Epoch 655/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2284 - mae: 0.8679 - val_loss: 1.7620 - val_mae: 1.0252\n",
            "Epoch 656/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2927 - mae: 0.8786 - val_loss: 1.7658 - val_mae: 1.0243\n",
            "Epoch 657/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2832 - mae: 0.8762 - val_loss: 2.3472 - val_mae: 1.2140\n",
            "Epoch 658/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3274 - mae: 0.8681 - val_loss: 1.7454 - val_mae: 1.0170\n",
            "Epoch 659/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1660 - mae: 0.8575 - val_loss: 1.8214 - val_mae: 1.0323\n",
            "Epoch 660/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3422 - mae: 0.9289 - val_loss: 1.7361 - val_mae: 1.0181\n",
            "Epoch 661/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2112 - mae: 0.8375 - val_loss: 2.1079 - val_mae: 1.1445\n",
            "Epoch 662/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2094 - mae: 0.8394 - val_loss: 2.1464 - val_mae: 1.1556\n",
            "Epoch 663/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2744 - mae: 0.8448 - val_loss: 2.2955 - val_mae: 1.2008\n",
            "Epoch 664/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2379 - mae: 0.8678 - val_loss: 1.7512 - val_mae: 1.0238\n",
            "Epoch 665/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1883 - mae: 0.8882 - val_loss: 1.7382 - val_mae: 1.0181\n",
            "Epoch 666/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2372 - mae: 0.8835 - val_loss: 2.1050 - val_mae: 1.1427\n",
            "Epoch 667/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1809 - mae: 0.8806 - val_loss: 1.7771 - val_mae: 1.0283\n",
            "Epoch 668/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2473 - mae: 0.8843 - val_loss: 1.7609 - val_mae: 1.0189\n",
            "Epoch 669/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2297 - mae: 0.8617 - val_loss: 1.7650 - val_mae: 1.0154\n",
            "Epoch 670/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2429 - mae: 0.8846 - val_loss: 1.7292 - val_mae: 1.0177\n",
            "Epoch 671/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2270 - mae: 0.8743 - val_loss: 1.8111 - val_mae: 1.0429\n",
            "Epoch 672/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3142 - mae: 0.9087 - val_loss: 2.1736 - val_mae: 1.1654\n",
            "Epoch 673/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3448 - mae: 0.8811 - val_loss: 3.2987 - val_mae: 1.4604\n",
            "Epoch 674/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3222 - mae: 0.9219 - val_loss: 2.0508 - val_mae: 1.1304\n",
            "Epoch 675/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1778 - mae: 0.8590 - val_loss: 2.0357 - val_mae: 1.1257\n",
            "Epoch 676/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2106 - mae: 0.8789 - val_loss: 1.9370 - val_mae: 1.0941\n",
            "Epoch 677/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1788 - mae: 0.8560 - val_loss: 1.7184 - val_mae: 1.0145\n",
            "Epoch 678/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1181 - mae: 0.8346 - val_loss: 2.0582 - val_mae: 1.1343\n",
            "Epoch 679/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1878 - mae: 0.8419 - val_loss: 2.8963 - val_mae: 1.3698\n",
            "Epoch 680/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2837 - mae: 0.8907 - val_loss: 1.7127 - val_mae: 1.0162\n",
            "Epoch 681/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1746 - mae: 0.8525 - val_loss: 2.0328 - val_mae: 1.1277\n",
            "Epoch 682/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1892 - mae: 0.8639 - val_loss: 1.7286 - val_mae: 1.0212\n",
            "Epoch 683/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1935 - mae: 0.8539 - val_loss: 2.3956 - val_mae: 1.2401\n",
            "Epoch 684/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2479 - mae: 0.8892 - val_loss: 1.8242 - val_mae: 1.0365\n",
            "Epoch 685/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1631 - mae: 0.8448 - val_loss: 2.2533 - val_mae: 1.1974\n",
            "Epoch 686/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2459 - mae: 0.8845 - val_loss: 1.7087 - val_mae: 1.0093\n",
            "Epoch 687/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1563 - mae: 0.8533 - val_loss: 2.0857 - val_mae: 1.1464\n",
            "Epoch 688/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1690 - mae: 0.8526 - val_loss: 1.7212 - val_mae: 1.0150\n",
            "Epoch 689/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3140 - mae: 0.8953 - val_loss: 2.0088 - val_mae: 1.1197\n",
            "Epoch 690/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2304 - mae: 0.8636 - val_loss: 1.9169 - val_mae: 1.0857\n",
            "Epoch 691/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2136 - mae: 0.8529 - val_loss: 2.8136 - val_mae: 1.3550\n",
            "Epoch 692/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2238 - mae: 0.8514 - val_loss: 2.4518 - val_mae: 1.2589\n",
            "Epoch 693/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1631 - mae: 0.8613 - val_loss: 1.7041 - val_mae: 1.0138\n",
            "Epoch 694/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2119 - mae: 0.8418 - val_loss: 1.7168 - val_mae: 1.0181\n",
            "Epoch 695/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1000 - mae: 0.8454 - val_loss: 1.7401 - val_mae: 1.0176\n",
            "Epoch 696/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2005 - mae: 0.8656 - val_loss: 1.7058 - val_mae: 1.0105\n",
            "Epoch 697/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2162 - mae: 0.8702 - val_loss: 1.6967 - val_mae: 1.0099\n",
            "Epoch 698/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1735 - mae: 0.8546 - val_loss: 1.7532 - val_mae: 1.0245\n",
            "Epoch 699/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2338 - mae: 0.8508 - val_loss: 1.7097 - val_mae: 1.0146\n",
            "Epoch 700/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1862 - mae: 0.8695 - val_loss: 1.9758 - val_mae: 1.1152\n",
            "Epoch 701/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1782 - mae: 0.8673 - val_loss: 1.7153 - val_mae: 1.0155\n",
            "Epoch 702/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2056 - mae: 0.8531 - val_loss: 3.2814 - val_mae: 1.4631\n",
            "Epoch 703/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3253 - mae: 0.8836 - val_loss: 1.8578 - val_mae: 1.0738\n",
            "Epoch 704/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1515 - mae: 0.8408 - val_loss: 2.1823 - val_mae: 1.1798\n",
            "Epoch 705/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1527 - mae: 0.8869 - val_loss: 1.6878 - val_mae: 1.0051\n",
            "Epoch 706/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1564 - mae: 0.8460 - val_loss: 1.8518 - val_mae: 1.0714\n",
            "Epoch 707/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1826 - mae: 0.8540 - val_loss: 2.0207 - val_mae: 1.1251\n",
            "Epoch 708/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3173 - mae: 0.8741 - val_loss: 1.6885 - val_mae: 1.0096\n",
            "Epoch 709/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3497 - mae: 0.8526 - val_loss: 1.7448 - val_mae: 1.0213\n",
            "Epoch 710/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1257 - mae: 0.8446 - val_loss: 1.7030 - val_mae: 1.0144\n",
            "Epoch 711/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1577 - mae: 0.8446 - val_loss: 1.6909 - val_mae: 1.0101\n",
            "Epoch 712/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2112 - mae: 0.8631 - val_loss: 1.7074 - val_mae: 1.0020\n",
            "Epoch 713/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1516 - mae: 0.8536 - val_loss: 1.7148 - val_mae: 1.0124\n",
            "Epoch 714/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1690 - mae: 0.8494 - val_loss: 1.6882 - val_mae: 1.0108\n",
            "Epoch 715/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1799 - mae: 0.8352 - val_loss: 2.4865 - val_mae: 1.2751\n",
            "Epoch 716/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2338 - mae: 0.8806 - val_loss: 1.7036 - val_mae: 1.0126\n",
            "Epoch 717/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1714 - mae: 0.8467 - val_loss: 1.6814 - val_mae: 1.0067\n",
            "Epoch 718/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1768 - mae: 0.8517 - val_loss: 1.7915 - val_mae: 1.0457\n",
            "Epoch 719/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0608 - mae: 0.8341 - val_loss: 1.6791 - val_mae: 1.0070\n",
            "Epoch 720/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1660 - mae: 0.8359 - val_loss: 1.6895 - val_mae: 1.0122\n",
            "Epoch 721/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1581 - mae: 0.8407 - val_loss: 1.9779 - val_mae: 1.1171\n",
            "Epoch 722/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1184 - mae: 0.8432 - val_loss: 1.7159 - val_mae: 1.0161\n",
            "Epoch 723/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2014 - mae: 0.8677 - val_loss: 1.8791 - val_mae: 1.0826\n",
            "Epoch 724/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1846 - mae: 0.8576 - val_loss: 1.8280 - val_mae: 1.0594\n",
            "Epoch 725/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2673 - mae: 0.8645 - val_loss: 2.0072 - val_mae: 1.1285\n",
            "Epoch 726/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0958 - mae: 0.8437 - val_loss: 1.7075 - val_mae: 1.0095\n",
            "Epoch 727/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3490 - mae: 0.8941 - val_loss: 1.9180 - val_mae: 1.1007\n",
            "Epoch 728/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1630 - mae: 0.8583 - val_loss: 2.2047 - val_mae: 1.1926\n",
            "Epoch 729/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1563 - mae: 0.8457 - val_loss: 1.8140 - val_mae: 1.0572\n",
            "Epoch 730/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2034 - mae: 0.8529 - val_loss: 1.6779 - val_mae: 1.0089\n",
            "Epoch 731/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2119 - mae: 0.8509 - val_loss: 1.9213 - val_mae: 1.1027\n",
            "Epoch 732/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1853 - mae: 0.8653 - val_loss: 1.6724 - val_mae: 1.0046\n",
            "Epoch 733/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1228 - mae: 0.8366 - val_loss: 1.8255 - val_mae: 1.0624\n",
            "Epoch 734/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2290 - mae: 0.8784 - val_loss: 1.6797 - val_mae: 1.0033\n",
            "Epoch 735/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1848 - mae: 0.8593 - val_loss: 1.6823 - val_mae: 1.0058\n",
            "Epoch 736/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4321 - mae: 0.8769 - val_loss: 2.1191 - val_mae: 1.1626\n",
            "Epoch 737/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1432 - mae: 0.8482 - val_loss: 1.7205 - val_mae: 1.0158\n",
            "Epoch 738/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0768 - mae: 0.8304 - val_loss: 1.9954 - val_mae: 1.1227\n",
            "Epoch 739/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1137 - mae: 0.8343 - val_loss: 1.7832 - val_mae: 1.0288\n",
            "Epoch 740/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1179 - mae: 0.8566 - val_loss: 1.8180 - val_mae: 1.0583\n",
            "Epoch 741/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2326 - mae: 0.8698 - val_loss: 2.5959 - val_mae: 1.3096\n",
            "Epoch 742/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1310 - mae: 0.8596 - val_loss: 1.6751 - val_mae: 1.0087\n",
            "Epoch 743/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1920 - mae: 0.8681 - val_loss: 1.7958 - val_mae: 1.0407\n",
            "Epoch 744/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1494 - mae: 0.8733 - val_loss: 1.7206 - val_mae: 1.0174\n",
            "Epoch 745/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1171 - mae: 0.8449 - val_loss: 1.7725 - val_mae: 1.0402\n",
            "Epoch 746/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1387 - mae: 0.8459 - val_loss: 1.6695 - val_mae: 1.0021\n",
            "Epoch 747/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2011 - mae: 0.8634 - val_loss: 1.6835 - val_mae: 1.0072\n",
            "Epoch 748/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1608 - mae: 0.8552 - val_loss: 1.7278 - val_mae: 1.0151\n",
            "Epoch 749/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1927 - mae: 0.8634 - val_loss: 1.7650 - val_mae: 1.0355\n",
            "Epoch 750/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1892 - mae: 0.8455 - val_loss: 1.7730 - val_mae: 1.0371\n",
            "Epoch 751/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1330 - mae: 0.8468 - val_loss: 1.6830 - val_mae: 1.0083\n",
            "Epoch 752/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0911 - mae: 0.8282 - val_loss: 1.7501 - val_mae: 1.0320\n",
            "Epoch 753/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0622 - mae: 0.8275 - val_loss: 2.0619 - val_mae: 1.1510\n",
            "Epoch 754/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1194 - mae: 0.8502 - val_loss: 1.6606 - val_mae: 1.0050\n",
            "Epoch 755/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1276 - mae: 0.8358 - val_loss: 1.6989 - val_mae: 1.0123\n",
            "Epoch 756/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1468 - mae: 0.8634 - val_loss: 1.8994 - val_mae: 1.0955\n",
            "Epoch 757/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2146 - mae: 0.8593 - val_loss: 1.8080 - val_mae: 1.0586\n",
            "Epoch 758/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0441 - mae: 0.8197 - val_loss: 1.8933 - val_mae: 1.0929\n",
            "Epoch 759/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1846 - mae: 0.8313 - val_loss: 2.5796 - val_mae: 1.3054\n",
            "Epoch 760/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1576 - mae: 0.8307 - val_loss: 1.7088 - val_mae: 1.0149\n",
            "Epoch 761/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0714 - mae: 0.8246 - val_loss: 1.8849 - val_mae: 1.0642\n",
            "Epoch 762/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2426 - mae: 0.8894 - val_loss: 2.1506 - val_mae: 1.1754\n",
            "Epoch 763/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2013 - mae: 0.8370 - val_loss: 2.0854 - val_mae: 1.1524\n",
            "Epoch 764/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2707 - mae: 0.8768 - val_loss: 1.9775 - val_mae: 1.1213\n",
            "Epoch 765/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2598 - mae: 0.8374 - val_loss: 1.6631 - val_mae: 1.0028\n",
            "Epoch 766/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1820 - mae: 0.8522 - val_loss: 1.7049 - val_mae: 1.0150\n",
            "Epoch 767/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2059 - mae: 0.8543 - val_loss: 1.7399 - val_mae: 1.0202\n",
            "Epoch 768/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1609 - mae: 0.8385 - val_loss: 1.6647 - val_mae: 1.0046\n",
            "Epoch 769/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0386 - mae: 0.8318 - val_loss: 1.7163 - val_mae: 1.0186\n",
            "Epoch 770/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1064 - mae: 0.8312 - val_loss: 1.9764 - val_mae: 1.1180\n",
            "Epoch 771/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3289 - mae: 0.8515 - val_loss: 2.0021 - val_mae: 1.1284\n",
            "Epoch 772/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2321 - mae: 0.8770 - val_loss: 1.6711 - val_mae: 1.0033\n",
            "Epoch 773/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0557 - mae: 0.8224 - val_loss: 1.7980 - val_mae: 1.0560\n",
            "Epoch 774/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2572 - mae: 0.8850 - val_loss: 1.6955 - val_mae: 1.0034\n",
            "Epoch 775/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0811 - mae: 0.8292 - val_loss: 1.6550 - val_mae: 0.9976\n",
            "Epoch 776/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2340 - mae: 0.8563 - val_loss: 2.1397 - val_mae: 1.1761\n",
            "Epoch 777/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2817 - mae: 0.8738 - val_loss: 1.7288 - val_mae: 1.0234\n",
            "Epoch 778/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1257 - mae: 0.8523 - val_loss: 1.6826 - val_mae: 1.0077\n",
            "Epoch 779/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1362 - mae: 0.8273 - val_loss: 2.0347 - val_mae: 1.1420\n",
            "Epoch 780/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0621 - mae: 0.8316 - val_loss: 1.6552 - val_mae: 1.0006\n",
            "Epoch 781/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1023 - mae: 0.8507 - val_loss: 1.6931 - val_mae: 1.0105\n",
            "Epoch 782/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2345 - mae: 0.8393 - val_loss: 1.6666 - val_mae: 1.0039\n",
            "Epoch 783/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1454 - mae: 0.8395 - val_loss: 1.6525 - val_mae: 0.9976\n",
            "Epoch 784/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0544 - mae: 0.8251 - val_loss: 2.0128 - val_mae: 1.1299\n",
            "Epoch 785/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2206 - mae: 0.8423 - val_loss: 1.8861 - val_mae: 1.0945\n",
            "Epoch 786/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1335 - mae: 0.8356 - val_loss: 1.7101 - val_mae: 1.0170\n",
            "Epoch 787/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0639 - mae: 0.8068 - val_loss: 1.8787 - val_mae: 1.0675\n",
            "Epoch 788/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1614 - mae: 0.8502 - val_loss: 1.9710 - val_mae: 1.1184\n",
            "Epoch 789/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0803 - mae: 0.8302 - val_loss: 2.2289 - val_mae: 1.2058\n",
            "Epoch 790/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1083 - mae: 0.8365 - val_loss: 1.6510 - val_mae: 1.0021\n",
            "Epoch 791/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1252 - mae: 0.8406 - val_loss: 1.6480 - val_mae: 1.0017\n",
            "Epoch 792/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0961 - mae: 0.8231 - val_loss: 1.7461 - val_mae: 1.0242\n",
            "Epoch 793/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1833 - mae: 0.8710 - val_loss: 1.7288 - val_mae: 1.0270\n",
            "Epoch 794/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2698 - mae: 0.8944 - val_loss: 1.7216 - val_mae: 1.0235\n",
            "Epoch 795/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1081 - mae: 0.8432 - val_loss: 2.0539 - val_mae: 1.1444\n",
            "Epoch 796/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0947 - mae: 0.8311 - val_loss: 1.7723 - val_mae: 1.0329\n",
            "Epoch 797/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2414 - mae: 0.8716 - val_loss: 1.9728 - val_mae: 1.1216\n",
            "Epoch 798/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1539 - mae: 0.8587 - val_loss: 1.6433 - val_mae: 0.9977\n",
            "Epoch 799/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0944 - mae: 0.8279 - val_loss: 1.6642 - val_mae: 1.0015\n",
            "Epoch 800/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1909 - mae: 0.8364 - val_loss: 1.7692 - val_mae: 1.0486\n",
            "Epoch 801/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1362 - mae: 0.8401 - val_loss: 1.7540 - val_mae: 1.0395\n",
            "Epoch 802/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2106 - mae: 0.8541 - val_loss: 2.2042 - val_mae: 1.1990\n",
            "Epoch 803/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1916 - mae: 0.8557 - val_loss: 1.6718 - val_mae: 1.0074\n",
            "Epoch 804/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0547 - mae: 0.8328 - val_loss: 1.9192 - val_mae: 1.1079\n",
            "Epoch 805/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0893 - mae: 0.8440 - val_loss: 1.6408 - val_mae: 0.9923\n",
            "Epoch 806/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1065 - mae: 0.8150 - val_loss: 2.1107 - val_mae: 1.1695\n",
            "Epoch 807/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0598 - mae: 0.8149 - val_loss: 2.2069 - val_mae: 1.1989\n",
            "Epoch 808/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2516 - mae: 0.8775 - val_loss: 2.1900 - val_mae: 1.1949\n",
            "Epoch 809/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1314 - mae: 0.8420 - val_loss: 2.0508 - val_mae: 1.1453\n",
            "Epoch 810/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1097 - mae: 0.8403 - val_loss: 1.6442 - val_mae: 0.9984\n",
            "Epoch 811/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1619 - mae: 0.8526 - val_loss: 1.6599 - val_mae: 1.0058\n",
            "Epoch 812/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1532 - mae: 0.8366 - val_loss: 1.6384 - val_mae: 0.9965\n",
            "Epoch 813/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0621 - mae: 0.8238 - val_loss: 1.6718 - val_mae: 1.0068\n",
            "Epoch 814/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1434 - mae: 0.8542 - val_loss: 1.6386 - val_mae: 0.9931\n",
            "Epoch 815/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2362 - mae: 0.8506 - val_loss: 2.1740 - val_mae: 1.1927\n",
            "Epoch 816/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1470 - mae: 0.8504 - val_loss: 1.8596 - val_mae: 1.0894\n",
            "Epoch 817/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1313 - mae: 0.8628 - val_loss: 1.6432 - val_mae: 1.0020\n",
            "Epoch 818/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1647 - mae: 0.8526 - val_loss: 1.6319 - val_mae: 0.9941\n",
            "Epoch 819/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1276 - mae: 0.8387 - val_loss: 1.9277 - val_mae: 1.1113\n",
            "Epoch 820/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1781 - mae: 0.8346 - val_loss: 2.1029 - val_mae: 1.1672\n",
            "Epoch 821/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0838 - mae: 0.8491 - val_loss: 1.6456 - val_mae: 1.0023\n",
            "Epoch 822/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1273 - mae: 0.8492 - val_loss: 1.6541 - val_mae: 1.0058\n",
            "Epoch 823/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1562 - mae: 0.8265 - val_loss: 2.0231 - val_mae: 1.1402\n",
            "Epoch 824/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2025 - mae: 0.8462 - val_loss: 2.3689 - val_mae: 1.2523\n",
            "Epoch 825/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1101 - mae: 0.8395 - val_loss: 1.8723 - val_mae: 1.0921\n",
            "Epoch 826/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1487 - mae: 0.8571 - val_loss: 1.6355 - val_mae: 0.9936\n",
            "Epoch 827/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1726 - mae: 0.8670 - val_loss: 1.7389 - val_mae: 1.0351\n",
            "Epoch 828/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1010 - mae: 0.8225 - val_loss: 1.7281 - val_mae: 1.0285\n",
            "Epoch 829/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1499 - mae: 0.8494 - val_loss: 1.7395 - val_mae: 1.0344\n",
            "Epoch 830/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1345 - mae: 0.8205 - val_loss: 1.6483 - val_mae: 1.0031\n",
            "Epoch 831/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0865 - mae: 0.8214 - val_loss: 1.6525 - val_mae: 1.0059\n",
            "Epoch 832/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1177 - mae: 0.8392 - val_loss: 1.7971 - val_mae: 1.0600\n",
            "Epoch 833/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1116 - mae: 0.8189 - val_loss: 1.6487 - val_mae: 1.0055\n",
            "Epoch 834/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1350 - mae: 0.8442 - val_loss: 1.6355 - val_mae: 0.9964\n",
            "Epoch 835/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0596 - mae: 0.8380 - val_loss: 1.7767 - val_mae: 1.0562\n",
            "Epoch 836/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0408 - mae: 0.8313 - val_loss: 1.7506 - val_mae: 1.0415\n",
            "Epoch 837/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0733 - mae: 0.8358 - val_loss: 2.0411 - val_mae: 1.1502\n",
            "Epoch 838/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0502 - mae: 0.8295 - val_loss: 1.8460 - val_mae: 1.0575\n",
            "Epoch 839/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0790 - mae: 0.8293 - val_loss: 1.6441 - val_mae: 0.9998\n",
            "Epoch 840/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1302 - mae: 0.8608 - val_loss: 1.6240 - val_mae: 0.9918\n",
            "Epoch 841/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1484 - mae: 0.8552 - val_loss: 1.6332 - val_mae: 0.9972\n",
            "Epoch 842/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1360 - mae: 0.8266 - val_loss: 1.9550 - val_mae: 1.1215\n",
            "Epoch 843/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0613 - mae: 0.8283 - val_loss: 2.4417 - val_mae: 1.2762\n",
            "Epoch 844/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1905 - mae: 0.8528 - val_loss: 1.6364 - val_mae: 0.9950\n",
            "Epoch 845/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1179 - mae: 0.8254 - val_loss: 1.6360 - val_mae: 0.9979\n",
            "Epoch 846/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2246 - mae: 0.8309 - val_loss: 1.9285 - val_mae: 1.1079\n",
            "Epoch 847/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0918 - mae: 0.8276 - val_loss: 1.8707 - val_mae: 1.0871\n",
            "Epoch 848/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1225 - mae: 0.8522 - val_loss: 2.2862 - val_mae: 1.2285\n",
            "Epoch 849/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2379 - mae: 0.8380 - val_loss: 2.4856 - val_mae: 1.2888\n",
            "Epoch 850/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1793 - mae: 0.8446 - val_loss: 2.2424 - val_mae: 1.2154\n",
            "Epoch 851/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0895 - mae: 0.8553 - val_loss: 1.6337 - val_mae: 0.9964\n",
            "Epoch 852/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1115 - mae: 0.8261 - val_loss: 1.6666 - val_mae: 0.9979\n",
            "Epoch 853/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0656 - mae: 0.8330 - val_loss: 1.8027 - val_mae: 1.0719\n",
            "Epoch 854/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0890 - mae: 0.8215 - val_loss: 1.6194 - val_mae: 0.9918\n",
            "Epoch 855/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1070 - mae: 0.8191 - val_loss: 1.6610 - val_mae: 1.0048\n",
            "Epoch 856/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2049 - mae: 0.8601 - val_loss: 1.6848 - val_mae: 1.0158\n",
            "Epoch 857/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2246 - mae: 0.8445 - val_loss: 1.6399 - val_mae: 0.9925\n",
            "Epoch 858/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1145 - mae: 0.8202 - val_loss: 1.7082 - val_mae: 1.0126\n",
            "Epoch 859/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0979 - mae: 0.8358 - val_loss: 1.6494 - val_mae: 1.0004\n",
            "Epoch 860/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2197 - mae: 0.8584 - val_loss: 1.6391 - val_mae: 0.9955\n",
            "Epoch 861/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0280 - mae: 0.8190 - val_loss: 1.6650 - val_mae: 1.0062\n",
            "Epoch 862/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0769 - mae: 0.8193 - val_loss: 1.6749 - val_mae: 1.0109\n",
            "Epoch 863/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0628 - mae: 0.8234 - val_loss: 1.9822 - val_mae: 1.1275\n",
            "Epoch 864/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2652 - mae: 0.8684 - val_loss: 1.7159 - val_mae: 1.0265\n",
            "Epoch 865/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1298 - mae: 0.8473 - val_loss: 1.7259 - val_mae: 1.0302\n",
            "Epoch 866/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0308 - mae: 0.8111 - val_loss: 2.0340 - val_mae: 1.1422\n",
            "Epoch 867/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0189 - mae: 0.8203 - val_loss: 1.6548 - val_mae: 1.0003\n",
            "Epoch 868/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1038 - mae: 0.8141 - val_loss: 1.7306 - val_mae: 1.0320\n",
            "Epoch 869/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0968 - mae: 0.8347 - val_loss: 1.6224 - val_mae: 0.9939\n",
            "Epoch 870/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0499 - mae: 0.8219 - val_loss: 1.6458 - val_mae: 1.0029\n",
            "Epoch 871/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1688 - mae: 0.8111 - val_loss: 1.6548 - val_mae: 1.0052\n",
            "Epoch 872/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1019 - mae: 0.8254 - val_loss: 1.7332 - val_mae: 1.0309\n",
            "Epoch 873/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0295 - mae: 0.7940 - val_loss: 1.7404 - val_mae: 1.0382\n",
            "Epoch 874/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1894 - mae: 0.8567 - val_loss: 2.1983 - val_mae: 1.2014\n",
            "Epoch 875/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0961 - mae: 0.8350 - val_loss: 1.7697 - val_mae: 1.0423\n",
            "Epoch 876/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1560 - mae: 0.8292 - val_loss: 1.6212 - val_mae: 0.9885\n",
            "Epoch 877/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1365 - mae: 0.8320 - val_loss: 2.5324 - val_mae: 1.2997\n",
            "Epoch 878/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2286 - mae: 0.8770 - val_loss: 1.7785 - val_mae: 1.0394\n",
            "Epoch 879/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1016 - mae: 0.8428 - val_loss: 1.8120 - val_mae: 1.0715\n",
            "Epoch 880/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1019 - mae: 0.8370 - val_loss: 1.7423 - val_mae: 1.0440\n",
            "Epoch 881/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1701 - mae: 0.8335 - val_loss: 1.7571 - val_mae: 1.0519\n",
            "Epoch 882/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1111 - mae: 0.8289 - val_loss: 2.4467 - val_mae: 1.2790\n",
            "Epoch 883/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1238 - mae: 0.8472 - val_loss: 1.7969 - val_mae: 1.0671\n",
            "Epoch 884/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1399 - mae: 0.8345 - val_loss: 1.9696 - val_mae: 1.1273\n",
            "Epoch 885/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1060 - mae: 0.8555 - val_loss: 1.6119 - val_mae: 0.9898\n",
            "Epoch 886/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1248 - mae: 0.8286 - val_loss: 1.8209 - val_mae: 1.0771\n",
            "Epoch 887/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1369 - mae: 0.8235 - val_loss: 2.2209 - val_mae: 1.2118\n",
            "Epoch 888/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0781 - mae: 0.8309 - val_loss: 1.6741 - val_mae: 1.0094\n",
            "Epoch 889/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0455 - mae: 0.8069 - val_loss: 2.6389 - val_mae: 1.3310\n",
            "Epoch 890/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1158 - mae: 0.8191 - val_loss: 1.9985 - val_mae: 1.1380\n",
            "Epoch 891/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1305 - mae: 0.8551 - val_loss: 1.7105 - val_mae: 1.0170\n",
            "Epoch 892/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2027 - mae: 0.8377 - val_loss: 1.8197 - val_mae: 1.0766\n",
            "Epoch 893/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0998 - mae: 0.8172 - val_loss: 1.6982 - val_mae: 1.0210\n",
            "Epoch 894/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1278 - mae: 0.8468 - val_loss: 1.8752 - val_mae: 1.0981\n",
            "Epoch 895/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1842 - mae: 0.8452 - val_loss: 1.6421 - val_mae: 0.9998\n",
            "Epoch 896/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2188 - mae: 0.8466 - val_loss: 1.6623 - val_mae: 0.9962\n",
            "Epoch 897/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0943 - mae: 0.8314 - val_loss: 2.2647 - val_mae: 1.2287\n",
            "Epoch 898/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0721 - mae: 0.8319 - val_loss: 1.6163 - val_mae: 0.9881\n",
            "Epoch 899/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1757 - mae: 0.8514 - val_loss: 1.6073 - val_mae: 0.9869\n",
            "Epoch 900/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1208 - mae: 0.8107 - val_loss: 2.3805 - val_mae: 1.2624\n",
            "Epoch 901/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1468 - mae: 0.8663 - val_loss: 1.6245 - val_mae: 0.9976\n",
            "Epoch 902/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1394 - mae: 0.8525 - val_loss: 1.6334 - val_mae: 0.9986\n",
            "Epoch 903/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0960 - mae: 0.8148 - val_loss: 1.7806 - val_mae: 1.0646\n",
            "Epoch 904/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0213 - mae: 0.8121 - val_loss: 1.6344 - val_mae: 0.9997\n",
            "Epoch 905/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0984 - mae: 0.8388 - val_loss: 1.9137 - val_mae: 1.1100\n",
            "Epoch 906/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1419 - mae: 0.8299 - val_loss: 1.6199 - val_mae: 0.9959\n",
            "Epoch 907/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1226 - mae: 0.8280 - val_loss: 1.6445 - val_mae: 0.9958\n",
            "Epoch 908/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0745 - mae: 0.8259 - val_loss: 1.6905 - val_mae: 1.0172\n",
            "Epoch 909/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1998 - mae: 0.8409 - val_loss: 1.6655 - val_mae: 0.9993\n",
            "Epoch 910/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0861 - mae: 0.8321 - val_loss: 1.8670 - val_mae: 1.0916\n",
            "Epoch 911/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1217 - mae: 0.8375 - val_loss: 1.6432 - val_mae: 0.9927\n",
            "Epoch 912/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0648 - mae: 0.8266 - val_loss: 1.6943 - val_mae: 1.0218\n",
            "Epoch 913/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0937 - mae: 0.8377 - val_loss: 1.6429 - val_mae: 1.0050\n",
            "Epoch 914/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0953 - mae: 0.8058 - val_loss: 1.6192 - val_mae: 0.9968\n",
            "Epoch 915/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1064 - mae: 0.8199 - val_loss: 1.6406 - val_mae: 0.9994\n",
            "Epoch 916/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1417 - mae: 0.8406 - val_loss: 1.7761 - val_mae: 1.0532\n",
            "Epoch 917/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1061 - mae: 0.8326 - val_loss: 1.6788 - val_mae: 1.0146\n",
            "Epoch 918/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0624 - mae: 0.8025 - val_loss: 1.6364 - val_mae: 0.9878\n",
            "Epoch 919/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1535 - mae: 0.8504 - val_loss: 1.7385 - val_mae: 1.0397\n",
            "Epoch 920/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0344 - mae: 0.8209 - val_loss: 1.6404 - val_mae: 1.0020\n",
            "Epoch 921/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0443 - mae: 0.7965 - val_loss: 1.9291 - val_mae: 1.1150\n",
            "Epoch 922/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1099 - mae: 0.8349 - val_loss: 1.8549 - val_mae: 1.0906\n",
            "Epoch 923/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1465 - mae: 0.8634 - val_loss: 1.6053 - val_mae: 0.9881\n",
            "Epoch 924/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1412 - mae: 0.8329 - val_loss: 1.6882 - val_mae: 1.0204\n",
            "Epoch 925/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0338 - mae: 0.8171 - val_loss: 1.6489 - val_mae: 0.9903\n",
            "Epoch 926/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2176 - mae: 0.8423 - val_loss: 1.7962 - val_mae: 1.0660\n",
            "Epoch 927/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0818 - mae: 0.8417 - val_loss: 1.6336 - val_mae: 0.9985\n",
            "Epoch 928/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1622 - mae: 0.8451 - val_loss: 1.6263 - val_mae: 0.9973\n",
            "Epoch 929/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1298 - mae: 0.8320 - val_loss: 1.6062 - val_mae: 0.9850\n",
            "Epoch 930/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0877 - mae: 0.8351 - val_loss: 1.6070 - val_mae: 0.9883\n",
            "Epoch 931/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0886 - mae: 0.8102 - val_loss: 1.6613 - val_mae: 1.0086\n",
            "Epoch 932/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1553 - mae: 0.8384 - val_loss: 1.6102 - val_mae: 0.9861\n",
            "Epoch 933/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0793 - mae: 0.8406 - val_loss: 1.6035 - val_mae: 0.9875\n",
            "Epoch 934/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1287 - mae: 0.8356 - val_loss: 2.2718 - val_mae: 1.2287\n",
            "Epoch 935/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0567 - mae: 0.8271 - val_loss: 1.6256 - val_mae: 0.9854\n",
            "Epoch 936/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1034 - mae: 0.8313 - val_loss: 1.8901 - val_mae: 1.1021\n",
            "Epoch 937/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0404 - mae: 0.8179 - val_loss: 1.6381 - val_mae: 1.0032\n",
            "Epoch 938/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1770 - mae: 0.8344 - val_loss: 1.7866 - val_mae: 1.0660\n",
            "Epoch 939/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1446 - mae: 0.8290 - val_loss: 2.0717 - val_mae: 1.1639\n",
            "Epoch 940/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0605 - mae: 0.8215 - val_loss: 1.6217 - val_mae: 0.9981\n",
            "Epoch 941/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1142 - mae: 0.8270 - val_loss: 1.7565 - val_mae: 1.0538\n",
            "Epoch 942/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0908 - mae: 0.8018 - val_loss: 1.7426 - val_mae: 1.0478\n",
            "Epoch 943/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0903 - mae: 0.8282 - val_loss: 1.6953 - val_mae: 1.0257\n",
            "Epoch 944/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1010 - mae: 0.8041 - val_loss: 2.1311 - val_mae: 1.1895\n",
            "Epoch 945/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2540 - mae: 0.8441 - val_loss: 1.7047 - val_mae: 1.0302\n",
            "Epoch 946/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1276 - mae: 0.8248 - val_loss: 2.2602 - val_mae: 1.2268\n",
            "Epoch 947/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1205 - mae: 0.8638 - val_loss: 1.6768 - val_mae: 1.0206\n",
            "Epoch 948/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0564 - mae: 0.8074 - val_loss: 1.8214 - val_mae: 1.0853\n",
            "Epoch 949/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0741 - mae: 0.8162 - val_loss: 1.7206 - val_mae: 1.0423\n",
            "Epoch 950/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1232 - mae: 0.8066 - val_loss: 1.6400 - val_mae: 0.9934\n",
            "Epoch 951/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0994 - mae: 0.8396 - val_loss: 1.6926 - val_mae: 1.0142\n",
            "Epoch 952/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1422 - mae: 0.8327 - val_loss: 1.6388 - val_mae: 1.0089\n",
            "Epoch 953/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0982 - mae: 0.8135 - val_loss: 1.6011 - val_mae: 0.9824\n",
            "Epoch 954/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2256 - mae: 0.8493 - val_loss: 1.6245 - val_mae: 0.9881\n",
            "Epoch 955/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0916 - mae: 0.8203 - val_loss: 1.5986 - val_mae: 0.9844\n",
            "Epoch 956/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0606 - mae: 0.8232 - val_loss: 1.9637 - val_mae: 1.1345\n",
            "Epoch 957/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0700 - mae: 0.8260 - val_loss: 1.8852 - val_mae: 1.1085\n",
            "Epoch 958/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1417 - mae: 0.8321 - val_loss: 1.5913 - val_mae: 0.9829\n",
            "Epoch 959/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0309 - mae: 0.8145 - val_loss: 1.5915 - val_mae: 0.9853\n",
            "Epoch 960/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0949 - mae: 0.8141 - val_loss: 2.0349 - val_mae: 1.1563\n",
            "Epoch 961/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1022 - mae: 0.8260 - val_loss: 1.7033 - val_mae: 1.0301\n",
            "Epoch 962/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1809 - mae: 0.8278 - val_loss: 1.7346 - val_mae: 1.0412\n",
            "Epoch 963/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1349 - mae: 0.8242 - val_loss: 2.2700 - val_mae: 1.2301\n",
            "Epoch 964/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0655 - mae: 0.8041 - val_loss: 1.6382 - val_mae: 1.0059\n",
            "Epoch 965/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1918 - mae: 0.8530 - val_loss: 1.6045 - val_mae: 0.9935\n",
            "Epoch 966/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0788 - mae: 0.8320 - val_loss: 1.9482 - val_mae: 1.1286\n",
            "Epoch 967/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1220 - mae: 0.8202 - val_loss: 1.9107 - val_mae: 1.1124\n",
            "Epoch 968/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0810 - mae: 0.8176 - val_loss: 1.6654 - val_mae: 1.0125\n",
            "Epoch 969/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1592 - mae: 0.8428 - val_loss: 1.7606 - val_mae: 1.0366\n",
            "Epoch 970/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2477 - mae: 0.8573 - val_loss: 1.8324 - val_mae: 1.0867\n",
            "Epoch 971/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0362 - mae: 0.8234 - val_loss: 1.5929 - val_mae: 0.9853\n",
            "Epoch 972/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0863 - mae: 0.8294 - val_loss: 1.6834 - val_mae: 1.0235\n",
            "Epoch 973/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0535 - mae: 0.8156 - val_loss: 1.6678 - val_mae: 1.0155\n",
            "Epoch 974/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0160 - mae: 0.8035 - val_loss: 1.9062 - val_mae: 1.1101\n",
            "Epoch 975/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0344 - mae: 0.8268 - val_loss: 1.6772 - val_mae: 1.0087\n",
            "Epoch 976/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0504 - mae: 0.8323 - val_loss: 1.5910 - val_mae: 0.9886\n",
            "Epoch 977/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0675 - mae: 0.8094 - val_loss: 1.6265 - val_mae: 1.0004\n",
            "Epoch 978/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0911 - mae: 0.8201 - val_loss: 2.0802 - val_mae: 1.1701\n",
            "Epoch 979/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1227 - mae: 0.8536 - val_loss: 1.6396 - val_mae: 1.0036\n",
            "Epoch 980/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0277 - mae: 0.8224 - val_loss: 1.6421 - val_mae: 0.9954\n",
            "Epoch 981/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0744 - mae: 0.8079 - val_loss: 1.5880 - val_mae: 0.9844\n",
            "Epoch 982/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0236 - mae: 0.8084 - val_loss: 1.6601 - val_mae: 1.0016\n",
            "Epoch 983/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.2038 - mae: 0.8447 - val_loss: 2.1273 - val_mae: 1.1883\n",
            "Epoch 984/1000\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 1.0449 - mae: 0.8157 - val_loss: 2.2660 - val_mae: 1.2325\n",
            "Epoch 985/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1579 - mae: 0.8615 - val_loss: 1.5881 - val_mae: 0.9854\n",
            "Epoch 986/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0897 - mae: 0.8128 - val_loss: 1.6887 - val_mae: 1.0256\n",
            "Epoch 987/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1206 - mae: 0.8246 - val_loss: 1.8367 - val_mae: 1.0875\n",
            "Epoch 988/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0307 - mae: 0.8091 - val_loss: 1.8684 - val_mae: 1.0986\n",
            "Epoch 989/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1345 - mae: 0.8445 - val_loss: 1.9968 - val_mae: 1.1369\n",
            "Epoch 990/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1568 - mae: 0.8625 - val_loss: 1.6717 - val_mae: 1.0182\n",
            "Epoch 991/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0616 - mae: 0.7951 - val_loss: 1.6087 - val_mae: 0.9942\n",
            "Epoch 992/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1177 - mae: 0.8360 - val_loss: 1.7957 - val_mae: 1.0661\n",
            "Epoch 993/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0574 - mae: 0.8146 - val_loss: 1.6648 - val_mae: 1.0051\n",
            "Epoch 994/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0194 - mae: 0.8129 - val_loss: 1.5994 - val_mae: 0.9894\n",
            "Epoch 995/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0666 - mae: 0.8272 - val_loss: 2.2221 - val_mae: 1.2160\n",
            "Epoch 996/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1026 - mae: 0.8136 - val_loss: 1.5958 - val_mae: 0.9908\n",
            "Epoch 997/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0329 - mae: 0.7941 - val_loss: 1.9006 - val_mae: 1.1083\n",
            "Epoch 998/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0458 - mae: 0.8304 - val_loss: 2.0226 - val_mae: 1.1536\n",
            "Epoch 999/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1215 - mae: 0.8532 - val_loss: 2.0847 - val_mae: 1.1732\n",
            "Epoch 1000/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0720 - mae: 0.8201 - val_loss: 1.8321 - val_mae: 1.0874\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5h86FEo80XhW",
        "colab_type": "text"
      },
      "source": [
        "## Convert the Tensorflow Model to Tensorflow Lite Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Egny1KLL0Wm0",
        "colab_type": "code",
        "outputId": "862ba727-88b7-4b6b-e67d-5c431ea5d18c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Convert the model to the TensorFlow Lite format with quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "tflite_model = converter.convert()\n",
        "open(\"model.tflite\", \"wb\").write(tflite_model)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2532"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFc5JmXo41H1",
        "colab_type": "text"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViQ7W8d-7PXK",
        "colab_type": "text"
      },
      "source": [
        "### Predict with Tensorflow Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkGzRSdA478s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "54e6b5c0-c15c-467e-f610-08b06d8a49bb"
      },
      "source": [
        "# Use the model to make predictions from our test data\n",
        "\n",
        "############################################################\n",
        "#@markdown How to use the model to predict the result with the test data (`x_test`) and save the result in a variable `predictions`?\n",
        "script = \"predictions =( y_test ==y_train)\" #@param {type:\"string\"}\n",
        "exec(script)\n",
        "############################################################"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeH5sWiu7RhT",
        "colab_type": "text"
      },
      "source": [
        "### Predict with Tensorflow Lite Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ET8_k-vvwop0",
        "colab_type": "code",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "af7c7877-28d1-432a-d758-bf6807376147"
      },
      "source": [
        "# Use the Tensorflow lite model to make interfences from our test data\n",
        "#@markdown Please choose and fill in correct code statements from one of the following:\n",
        "#@markdown 1. interpreter.invoke() \n",
        "#@markdown 2. interpreter_input().fill(x_test[i])\n",
        "#@markdown 3. interpreter = tf.lite.Interpreter('model.tflite')\n",
        "#@markdown 4. interpreter_predictions[i] = interpreter_output()[0]\n",
        "#@markdown 5. interpreter_output = interpreter.tensor(interpreter.get_output_details()[0][\"index\"])\n",
        "#@markdown 6. interpreter_input = interpreter.tensor(interpreter.get_input_details()[0][\"index\"])\n",
        "\n",
        "############################################################\n",
        "# Instantiate an interpreter for the TFLite model\n",
        "#@markdown Which is the statement to instantiate an interpreter with a TFLite Model named `model.tflite`?\n",
        "script_1 = \"interpreter = tf.lite.Interpreter('model.tflite')\" #@param {type:\"string\"}\n",
        "exec(script_1)\n",
        "############################################################\n",
        "\n",
        "# Allocate memory for the model\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "############################################################\n",
        "# Get the input tensors so we can feed in values \n",
        "#@markdown Which is the statement to get input sensors?\n",
        "script_2 = \"interpreter_input = interpreter.tensor(interpreter.get_input_details()[0][\\\"index\\\"])\" #@param {type:\"string\"}\n",
        "exec(script_2)\n",
        "############################################################\n",
        "\n",
        "############################################################\n",
        "# Get the output tensors so we can get the results\n",
        "#@markdown Which is the statement to get output sensors?\n",
        "script_3 = \"interpreter_output = interpreter.tensor(interpreter.get_output_details()[0][\\\"index\\\"])\" #@param {type:\"string\"}\n",
        "exec(script_3)\n",
        "############################################################\n",
        "\n",
        "# Create arrays to store the results\n",
        "interpreter_predictions = np.empty(x_test.size)\n",
        "\n",
        "# Run each model's interpreter for each value and store the results in arrays\n",
        "for i in range(x_test.size):\n",
        "  ############################################################\n",
        "  #@markdown Which is the statement to fill the input of the interpreter with `x_test[i]`?\n",
        "  script_4 = \"interpreter_input().fill(x_test[i])\" #@param {type:\"string\"}\n",
        "  exec(script_4)\n",
        "  ############################################################\n",
        "  ############################################################\n",
        "  #@markdown Which is the statement to invoke the interpreter?\n",
        "  script_5 = \"interpreter.invoke() \" #@param {type:\"string\"}\n",
        "  exec(script_5)\n",
        "  ############################################################\n",
        "  ############################################################\n",
        "  #@markdown Which is the statement to get the output from the interpreter and save the output in `interpreter_predictions[i]`?\n",
        "  script_6 = \"interpreter_predictions[i] = interpreter_output()[0]\"#@param {type:\"string\"}\n",
        "  exec(script_6)\n",
        "  ############################################################\n",
        "\n",
        "\n",
        "# Make the shape of the y_test be the same as the predictions\n",
        "y_test = np.reshape(y_test, predictions.shape)\n",
        "# Make the shape of the interpreter_predictions be the same as the predictions\n",
        "interpreter_predictions = np.reshape(interpreter_predictions, predictions.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-eb9c32d01d4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# Make the shape of the y_test be the same as the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;31m# Make the shape of the interpreter_predictions be the same as the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0minterpreter_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterpreter_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'bool' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciEdnWpc1rR5",
        "colab_type": "text"
      },
      "source": [
        "## Plot the Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svBsN_bVu1HL",
        "colab_type": "code",
        "outputId": "0f8aa6cf-9c3d-4dbe-b203-8ab7d555bb71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 664
        }
      },
      "source": [
        "plt.clf()\n",
        "plt.title('Test data predicted vs actual values')\n",
        "plt.plot(x_test, y_test, 'b.', label='Actual')\n",
        "plt.plot(x_test, predictions, 'r.', label='Predicted (tensorflow)')\n",
        "############################################################\n",
        "#@markdown Please write the statement to plot the outputs in green dots with a label `Predicted (tflite)` from the interpreter.\n",
        "script = \"plt.plot(predicted, 'g.', label='Training loss')\"#@param {type:\"string\"}\n",
        "exec(script)\n",
        "############################################################\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-fcb344b1e526>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test data predicted vs actual values'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Actual'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Predicted (tensorflow)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m############################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#@markdown Please write the statement to plot the outputs in green dots with a label `Predicted (tflite)` from the interpreter.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2761\u001b[0m     return gca().plot(\n\u001b[1;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2763\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \"\"\"\n\u001b[1;32m   1645\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1646\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1647\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (40,) and (1,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEICAYAAABGaK+TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAY3klEQVR4nO3df5DkdX3n8edrZ1lARYFlswK7xxJBLU4iJHPARI+bsHhulAtUSRF/srnDLHdHEji9U1YrKlED1qUU7khp9kBdw+9jMRAupXCLE+4uE8Ks4EVYU+Lya8nCDriri6esu/O+Pz6flqaZnu7p6V+f7tejaqq/P3q+/fl0T7/m0+/vj1ZEYGZm5VnU6waYmVlrHOBmZoVygJuZFcoBbmZWKAe4mVmhHOBmZoVygA8oSY9JOrPX7WiH6r5I+pika7rwmOOStnf6cfqBpAlJH+zAdgfmb7BfOcA7QNLzVT8zkn5aNf++FrbXkTdY1fZD0nGd2n47RcQfR0TD50LSVyV9phtt6rZB7pvNz+JeN2AQRcSrKtOSHgM+GBH/s3ct6h+SFkfEvl63w2wQeATeRZIWSbpU0g8kPSfpFkmH53UHSbouL98t6X5JyyV9FvjnwNV5BH91nW1/QNLj+fc/XrPuFEmTebs7JF0taUled2++23fy9n9b0mGS7pQ0LWlXnl4xR78ek7Re0sP5/l+RdFBeNy5pu6SPSnoa+Mpcz0MTffmUpOuq5t8q6W9y356U9DuS1gHvAz6S+/SX+b5HSdqU+/WopD+o2s7BeWS7S9LDwD+bo79flPQnNctul/ShPP1RSU9J2iPpHyStrrOdd0p6QNKPc9s/VbN+Pn17yaeo6lH6fF/Pqm0clT89Vr82J0t6VtIBkl4n6Z78Oj0r6XpJh9bZ1ks+NaimRNXgtTlF0lR+np6R9PlGbR8aEeGfDv4AjwFn5umLgb8FVgAHAn8G3JjXXQj8JfAKYAT4NeDVed0EaRRf7zFOAJ4HTs/b/Tywr+pxfw04jfSJaxWwFbik6vcDOK5qfinwrtyWQ4D/DvxFgz5+F1gJHA78H+Azed14bsvnctsObvA8NOrLp4Dr8vQxwB7gPcABud0n5XVfrbQhzy8CtgCfAJYAvwxsA96e118B/K/c/pW5P9vr9Pd04ElAef4w4KfAUcAb8rqj8rpVwOvqbGccODG37VeAZ4Bz5tu3Oq/hL+7T6PVkjr8v4B7gd6vm/zPwpTx9HPC2/DotA+4Frqzzt1/7eoxXnt8mXptJ4AN5+lXAab1+X/fLT88bMOg/NX/EW4HVVeuOBH5OCtZ/A/wN8CuzbKPuGyyv/wRwU9X8K4G9lced5f6XAF+vmn/Jm3+W+58E7GrQx39bNf8O4Ad5ejy35aCq9XM9D3P2hZcG+PrqftS0qTYwTgWeqLnPeuAreXobsKZq3TrqB7iAJ4DT8/zvAvfk6eOAncCZwAHz/Fu5EvjCfPs222s4233qvZ5z/X0BH6zqm0j/nE6vc99zgAfq/O3Xvh7jvBjgjV6be4HLgCPm83wOw49r4N11DPB1STNVy/YDy4E/J438bsofQ68DPh4RP29iu0eR3lgARMRPJD1XmZf0etJIdpQ0CltMGvHMStIrgC8Aa0ijS4BDJI1ExP46v/Zk1fTjuU0V0xHxs6r5uZ6HOftSYyXwg3r9qHEMcJSk3VXLRkijbmofN/dhVhERkm4ijY7vBd5Ler2IiEckXUL6R/NPJX0T+FBE/GPtdiSdShr5v4k08jyQNDqeb9/m1OLrWbEJ+K+SjgReD8yQnzNJy4GrSCW+Q0gj6V0tNLHRa3MB8EfA9yQ9ClwWEXe28DgDxzXw7noS+M2IOLTq56CIeCoifh4Rl0XECcCvA2cB5+ffa3TJyB2kNzzwizfs0qr1XwS+BxwfEa8GPkYaTdXzYVIp4NR8/9Mrm57jd1ZWTf8ToDqwattf93looi+123ldnXWzPeajNY95SES8I69/yePmPszlRuBcSceQRpCbfvHAETdExFtJwRSk8tFsbgDuAFZGxGuAL/HiczyfvgH8P9I/54rXVk238nqmB4rYBdwF/DbpH9VNkYfFwB/ntpyYt/v+Obb5kznaN+drExHfj4j3AL9Eei5vlfTKRm0fBg7w7voS8Nn8pkfSMkln5+nfkHSipBHgx6SSQmWE+gypLljPrcBZeafXEtJopfq1PSRv83lJbwT+Xc3v127/EFJNd3fegfXJJvp2kaQV+f4fB26e4751n4cm+lLteuBMSedJWixpqaST6vTp74A9eQfjwZJGJL1JUmVn5S3A+rzDbwXw+3N1NiIeAJ4FrgG+GRG7c1/eIOkMSQcCPyM9jzN1NnMI8MOI+JmkU0gB2UrfAB4E3pv7tQb4FzWPM9/Xs9oNpMHEuXm6ervPAz+SdDTwn+bYxoPAOyQdLum1pDJexZyvjaT3S1oWETNAZZRe7zkdKg7w7rqKNOK6S9Ie0o68U/O615LC68ekGvFfk8oqld87Nx9B8F9qNxoRDwEXkd5cO0gfY6tPQvmPpHDYA/w3Xh6unwI25qMdziPVYg8mBdTfAt9oom83kEZq20gf/ec6Trnu89BEX34hIp4g1ds/DPyQFBJvzquvBU7IffqLXCo4i1T/fZQXw/c1+f6Xkcomj+Z+VJ77Rn0+k5eG2oGkssizwNOkUeP6Or//74E/ys/BJ0j/RObdt7zsYuBfkQLufUBlObT2ela7AzgeeDoivlO1/DLgV4EfAf8DuG2Obfw58B1SXfwuqv4Gm3ht1gAPSXqe9Lfz7oj46Tz7MJD04qchs9bIx7qb9YRH4GZmhXKAm5kVyiUUM7NCeQRuZlaorp7Ic8QRR8SqVau6+ZBmZsXbsmXLsxGxrHZ5VwN81apVTE1NdfMhzcyKJ2nWM4NdQjEzK1RTI/B8nO8e0vUq9kXEaD6j62bS1dYeA87Lp92amVkXzGcE/hsRcVJEjOb5S4HNEXE8sDnPm5lZlyykhHI2sDFPbyRdStLMzLqk2QAP0nUrtih9IwjA8ojYkaefJl0K9GUkrcvfpjE1PT29wOaamVlFs0ehvDUinpL0S8Ddkr5XvTJfH3nWM4IiYgOwAWB0dNRnDZmZtUlTI/B8nWYiYifwdeAU4Jl8kXfy7c5ONdLMrFSTk3D55em23RqOwPOF0xdFxJ48/S9J12i+A1hLunTmWuD29jfPzKxck5OwejXs3QtLlsDmzTA21r7tN1NCWU76+qvK/W+IiG9Iuh+4RdIFpOson9e+ZpmZlW9iIoX3/v3pdmKiywEeEdt48ULy1cufA1a3rylmZoNlfDyNvCsj8PHx9m7fX2psZtYhY2OpbDIxkcK7naNvcICbmXXU2Fj7g7vC10IxMyuUA9zMrFAOcDOzQjnAzcwK5QA3MyuUA9zMrFAOcDOzQjnAzcxatGEDvP3t6bYXfCKPmVkLNmyACy9M03fdlW7Xrat//07wCNzMrAWbNs093w0OcDOzFrzrXXPPd4NLKGZmLaiUSzZtSuHd7fIJOMDNzFq2bl1vgrvCJRQzs0I5wM3MCuUANzMrlAPczKxQDnAzs0I5wM3MCuUANzMrlAPczKxQDnAzs0I5wM3MCuUANzMrlAPczKxQTQe4pBFJD0i6M88fK+k+SY9IulnSks4108yscyYn4fLL021J5jMCvxjYWjX/OeALEXEcsAu4oJ0NMzPrhslJWL0a/vAP021JId5UgEtaAbwTuCbPCzgDuDXfZSNwTicaaGbWSRMTsHcv7N+fbicmet2i5jU7Ar8S+Agwk+eXArsjYl+e3w4cPdsvSlonaUrS1PT09IIaa2bWbuPjsGQJjIyk2/HxXreoeQ0DXNJZwM6I2NLKA0TEhogYjYjRZcuWtbIJM7OOGRuDzZvh059Ot2NjvW5R85r5Rp63AL8l6R3AQcCrgauAQyUtzqPwFcBTnWummVnnjI2VFdwVDUfgEbE+IlZExCrg3cA9EfE+4FvAuflua4HbO9ZKMzN7mYUcB/5R4EOSHiHVxK9tT5PMzKwZ8/pS44iYACby9DbglPY3yczMmuEzMc3MCuUANzMrlAPczKxQDnAzs0I5wM3MCuUANzMrlAPczKxQDnAzs0I5wM3MCuUANzMrlAPczKxQDnAzs0I5wM3MCuUANzMrlAPczKxQDnAzs0I5wM3MCuUANzMrlAPczKxQDnAzs0I5wM3MCuUANzMrlAPczKxQDnAzs0I5wM3MCuUANzMrlAPczKxQDQNc0kGS/k7SdyQ9JOmyvPxYSfdJekTSzZKWdL65ZmZW0cwI/AXgjIh4M3ASsEbSacDngC9ExHHALuCCzjXTzMxqNQzwSJ7PswfknwDOAG7NyzcC53SkhWZmNqumauCSRiQ9COwE7gZ+AOyOiH35LtuBo+v87jpJU5Kmpqen29FmMzOjyQCPiP0RcRKwAjgFeGOzDxARGyJiNCJGly1b1mIzzcys1ryOQomI3cC3gDHgUEmL86oVwFNtbpuZmc2hmaNQlkk6NE8fDLwN2EoK8nPz3dYCt3eqkWZm9nKLG9+FI4GNkkZIgX9LRNwp6WHgJkmfAR4Aru1gO83MrEbDAI+I/wucPMvybaR6uJmZ9YDPxDQzK5QD3MysUA5wM7NCOcDNzArlADczK5QD3MysUA5wM7NCOcDNzArlADczK5QD3Mx6YnISLr883VprmrkWiplZW01OwurVsHcvLFkCmzfD2FivW1Uej8DNrOsmJlJ479+fbicmet2iMjnAzazrxsfTyHtkJN2Oj/e6RWVyCcXMum5sLJVNJiZSeLt80hoHuJl13OTky8N6bMzBvVAOcDPrKO+w7BzXwM2so7zDsnMc4GbWUd5h2TkuoZhZR3mHZec4wM2s7Wp3WnqHZWc4wM2srbzTsntcAzeztvJOy+5xgJtZW3mnZfe4hGJmbeWdlt3jADeztvNOy+5wCcXMrFAOcDNrG39JQ3c1LKFIWgl8DVgOBLAhIq6SdDhwM7AKeAw4LyJ2da6pZtZPao/1rhw++MILaQfm1VfDunW9buVga6YGvg/4cER8W9IhwBZJdwO/A2yOiCskXQpcCny0c001s34x27HeExMpvGdm0s9FF8GJJ7oW3kkNSygRsSMivp2n9wBbgaOBs4GN+W4bgXM61Ugz6y+zHes9Pp5G3hUzMz4GvNPmVQOXtAo4GbgPWB4RO/Kqp0klltl+Z52kKUlT09PTC2iqmfWL2Y71HhtLZZPFi2HRIjjwQB8D3mmKiObuKL0K+GvgsxFxm6TdEXFo1fpdEXHYXNsYHR2NqampBTXYzPrDbF/SMNdya52kLRExWru8qePAJR0AbAKuj4jb8uJnJB0ZETskHQnsbF9zzazf1TvW28eAd08zR6EIuBbYGhGfr1p1B7AWuCLf3t6RFppZT1VG1EuXwnPPeWTdT5oZgb8F+ADw95IezMs+RgruWyRdADwOnNeZJppZr1QfGjgzAxIccEAKdId47zUM8Ij434DqrF7d3uaYWT+pHG0yM5PmI9L8177mAO8HPhPTzOqqHG2iekM46ykHuJnVVbmy4IUXptKJlA4PPP/8XrfMwFcjNLMGKkeVnH++Dw/sNw5wM2uKDw/sPy6hmJkVygFuZlYoB7iZWaEc4GZmhXKAm5kVygFuNmT8tWeDw4cRmg2R2b5Jx4cGlssjcLMhMts36Vi5HOBmQ2S2b9KxcrmEYjZEKtc28Snxg8EBbjZkfEr84HAJxcysUA5wM7NCOcDNBpyP+x5croGbDTAf9z3YPAI3G2A+7nuwOcDNBkC9MomP+x5sLqGYFW6uMomP+x5sDnCzws1WJqkOah/3PbhcQjErnMskw8sjcLPCuUwyvBzgZgPAZZLh5BKKmVmhGga4pC9L2inpu1XLDpd0t6Tv59vDOttMMzOr1cwI/KvAmppllwKbI+J4YHOeNzOzLmoY4BFxL/DDmsVnAxvz9EbgnDa3y8zMGmi1Br48Inbk6aeB5fXuKGmdpClJU9PT0y0+nJlV8wWqDNpwFEpEhKSYY/0GYAPA6Oho3fuZWXN8gSqraHUE/oykIwHy7c72NcnM5uILVFlFqwF+B7A2T68Fbm9Pc8ysEZ95aRUNSyiSbgTGgSMkbQc+CVwB3CLpAuBx4LxONtJsGExONnc2pc+8tIqGAR4R76mzanWb22I2tOZb1/aZlwY+E9OsL7iuba1wgJv1Ade1rRW+mJVZH3Bd21rhADfrE65r23y5hGJmVigHuJlZoRzgZmaFcoCbmRXKAW5mVigHuFkH+bKv1kk+jNCsQ3zZV+s0j8DNOsSnx1unOcDNOsSnx1unuYRi1ia1l4P16fHWaQ5wszaoV+/26fHWSS6hmLWB693WCw5wszZwvdt6wSUUs1k0+/VmFa53Wy84wM1qtHr8tuvd1m0uoZjVcD3bSuEAN6vheraVwiUUsxquZ1spHOBmVSo7L5cu7XVLzBpzgJtllZ2XL7wAMzOwaBEceKAvQmX9yzVws6yy83JmJs3PzHgnpvU3B7gNtPlcj7uy83JRflcsWuSdmNbfFlRCkbQGuAoYAa6JiCva0qoa8z2pwgzmfzx39c7LpUvhuef8N2f9reUAlzQC/CnwNmA7cL+kOyLi4XY1DnxRfGvdbMdzN/rb8ck4VpKFlFBOAR6JiG0RsRe4CTi7Pc16kU+qsFYtXQpSa6UQfxWalWAhJZSjgSer5rcDpy6sOS9XqUtWRuCuR1ozJifhkkvSjsiREbjyyuZH1v7UZ6Xo+E5MSeskTUmamp6envfvV+qSn/6030jWvOojSmZmUj17vr/rT33W7xYyAn8KWFk1vyIve4mI2ABsABgdHY1WHsh1SavVaMf2Qj65+VOflWIhAX4/cLykY0nB/W7gvW1pVZv46JXB1EyJYyGnw/tUeitFywEeEfsk/R7wTdJhhF+OiIfa1rIFch1zcDV7dMlCPrn5U5+VYEE18Ij4q4h4fUS8LiI+265GtYPrmOVqdASIrxZolgzstVBcxyxTp8sjZoOk2ABvVN/2m7xM3SiPmA2KIgO82fq23+Tl8Scns+YVGeCtnCJtZfAnJ7PmFRngHqUNNn9yMmtOkQHuUZqZWaEBDh6lmZn5Cx3m4CvSmVk/K3YE3mk+k7P9fGkDs/ZygNfhI13ay/8QzdrPJZQ6Zjtd2yWV1vnSBmbt5xF4HbVHusBgjiC7VdbwoZ9m7ecAn0P1kS6XX97fJZVWgribZQ0f+mnWfg7wJvXzCLLZIK4N+W7X+X3op1l7OcCb1MsRZHXwwsvb0EwQzxby/fxPycwac4DPQy9GkNXBOzKSvmV9374UuFdemb7rcenSxkE8W8ivX++yhlnJHOB9rjp4Z2bSsgh44QW46KI0XR3m8/2OSJc1zMrlAO9z1cFbPQJftOjFUN+7N4X3+vX1t+OdiGaDxwHe52Y7nHFiIpVNLrlkfvVrj7bNBosDvAC1wVuZPvFEj6jNhpkDvGAeUZsNN59Kb2ZWKAe4mVmhHOBmZoVygJuZFcoBbmZWKAe4mVmhFBHdezBpGni8wd2OAJ7tQnP60bD2fVj7De77MPa9lX4fExHLahd2NcCbIWkqIkZ73Y5eGNa+D2u/wX0fxr63s98uoZiZFcoBbmZWqH4M8A29bkAPDWvfh7Xf4L4Po7b1u+9q4GZm1px+HIGbmVkTHOBmZoXqqwCXtEbSP0h6RNKlvW5PN0haKelbkh6W9JCki3vdpm6TNCLpAUl39rot3STpUEm3SvqepK2ShuLiwJL+Q/5b/66kGyUd1Os2dYqkL0vaKem7VcsOl3S3pO/n28Na3X7fBLikEeBPgd8ETgDeI+mE3raqK/YBH46IE4DTgIuGpN/VLga29roRPXAV8I2IeCPwZobgOZB0NPAHwGhEvAkYAd7d21Z11FeBNTXLLgU2R8TxwOY835K+CXDgFOCRiNgWEXuBm4Cze9ymjouIHRHx7Ty9h/QmPrq3reoeSSuAdwLX9Lot3STpNcDpwLUAEbE3Inb3tlVdsxg4WNJi4BXAP/a4PR0TEfcCP6xZfDawMU9vBM5pdfv9FOBHA09WzW9niIIMQNIq4GTgvt62pKuuBD4CzPS6IV12LDANfCWXj66R9MpeN6rTIuIp4E+AJ4AdwI8i4q7etqrrlkfEjjz9NLC81Q31U4APNUmvAjYBl0TEj3vdnm6QdBawMyK29LotPbAY+FXgixFxMvATFvBRuhS53ns26R/YUcArJb2/t63qnUjHcbd8LHc/BfhTwMqq+RV52cCTdAApvK+PiNt63Z4uegvwW5IeI5XMzpB0XW+b1DXbge0RUfm0dSsp0AfdmcCjETEdET8HbgN+vcdt6rZnJB0JkG93trqhfgrw+4HjJR0raQlpx8YdPW5Tx0kSqQ66NSI+3+v2dFNErI+IFRGxivR63xMRQzEai4ingSclvSEvWg083MMmdcsTwGmSXpH/9lczBDtva9wBrM3Ta4HbW91Q33wrfUTsk/R7wDdJe6a/HBEP9bhZ3fAW4APA30t6MC/7WET8VQ/bZN3x+8D1ecCyDfjXPW5Px0XEfZJuBb5NOgLrAQb4lHpJNwLjwBGStgOfBK4AbpF0Aeny2ue1vH2fSm9mVqZ+KqGYmdk8OMDNzArlADczK5QD3MysUA5wM7NCOcDNzArlADczK9T/B/clrgZE1cvoAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}